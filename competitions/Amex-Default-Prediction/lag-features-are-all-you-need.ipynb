{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "lag-features-are-all-you-need.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lag Features Are All You Need\n",
        "\n",
        "> **Credits:** Based on [this](https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7963) amazing notebook.\n",
        "\n",
        "OK. Maybe not **all** you need.\n",
        "<br>\n",
        "But they improve `LightGBM`!\n",
        "_____\n",
        "\n",
        "\n",
        "This notebook stated as an ensemble of `LightGBM` + `Catboost` + `XGB` but while running it I discovered an interestin idea that worked really well.\n",
        "\n",
        "### Lag Features\n",
        "\n",
        "On this competition we get information about clients of AMEX over time. \n",
        "Most high scoring notebooks on this competiion focused on aggregating the information per client and create a single row of extracted features: One for each client.\n",
        "\n",
        "**One of such agg function is `last`**.\n",
        "\n",
        "Quick examination revealed that the `last` feature is extreamly powerful at predicting if the client defaults or not (well.. make sense..). \n",
        "So I took this two steps further: \n",
        "\n",
        "- **First feature:** Just like the `last` feature: I added a `first` feature. \n",
        "- **\"Lag\" fearures:** to capture the change over time about each client I calculated two features for every `first`, `last` pair:\n",
        "     - **Last - First:** The change since we first see the client to the last time we see the client.\n",
        "     - **Last / First:** The fractional difference since we first see the client to the last time we see the client.\n",
        "\n",
        "This improved my `LightGBM` model to the point that it overtook the whole `LightGBM` + `Catboost` + `XGB` ensemble.\n",
        "\n",
        "I uploaded a dataset containing the extracted lag features and updated the final model predictions (only `LightGBM` this time) for everyone to play with. \n",
        "\n",
        "<br>\n",
        "\n",
        "_____\n",
        "\n",
        "**Next Experiement (currently running):** More \"lag features\" variations - Also take in consideration other indices of the time-series. will keep you updated.\n",
        "_____\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.003629,
          "end_time": "2022-06-19T23:15:37.769935",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.766306",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Ta6oxF1uuzlq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing for colab"
      ],
      "metadata": {
        "id": "whFMYLB1u7rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "MwbPTJbLu1oU",
        "outputId": "3a23322f-edf0-4b64-d42a-fd83b1cf4d6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.0.6-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 131 kB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.6.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Lx3ZHpcHvLK0",
        "outputId": "6a478f6f-f7ed-41b2-bdb3-1ca40aaa90ba",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-21a6deaf-96d0-4d8f-9818-2149ce5d74de\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-21a6deaf-96d0-4d8f-9818-2149ce5d74de\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 62 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c amex-default-prediction -f sample_submission.csv\n",
        "!unzip /content/sample_submission.csv.zip"
      ],
      "metadata": {
        "id": "jeIvlVN0vQ08",
        "outputId": "b9bda015-8c7c-4cd4-cca7-aa728c4e94c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading sample_submission.csv.zip to /content\n",
            " 96% 31.0M/32.4M [00:00<00:00, 92.9MB/s]\n",
            "100% 32.4M/32.4M [00:00<00:00, 93.0MB/s]\n",
            "Archive:  /content/sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c amex-default-prediction -f train_labels.csv\n",
        "!unzip /content/train_labels.csv.zip"
      ],
      "metadata": {
        "id": "PfGNoPMDxoPk",
        "outputId": "4a8ee73d-fa70-4b83-b3db-9ed9cd9b61eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading train_labels.csv.zip to /content\n",
            "\r  0% 0.00/16.2M [00:00<?, ?B/s]\r 86% 14.0M/16.2M [00:00<00:00, 145MB/s]\n",
            "\r100% 16.2M/16.2M [00:00<00:00, 159MB/s]\n",
            "Archive:  /content/train_labels.csv.zip\n",
            "  inflating: train_labels.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d raddar/amex-data-integer-dtypes-parquet-format\n",
        "!unzip /content/amex-data-integer-dtypes-parquet-format.zip"
      ],
      "metadata": {
        "id": "q8p7BzCIvSAK",
        "outputId": "29f146d2-32d4-4600-c255-2d5ebcd69048",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading amex-data-integer-dtypes-parquet-format.zip to /content\n",
            "100% 4.06G/4.07G [00:17<00:00, 317MB/s]\n",
            "100% 4.07G/4.07G [00:17<00:00, 251MB/s]\n",
            "Archive:  /content/amex-data-integer-dtypes-parquet-format.zip\n",
            "  inflating: test.parquet            \n",
            "  inflating: train.parquet           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.002235,
          "end_time": "2022-06-19T23:15:37.774992",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.772757",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "-p0d_9druzlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Library\n",
        "# ====================================================\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "from tqdm.auto import tqdm\n",
        "import itertools\n",
        "\n",
        "# ====================================================\n",
        "# Read & preprocess data and save it to disk\n",
        "# ====================================================\n",
        "def read_preprocess_data():\n",
        "    train = pd.read_parquet('/content/train.parquet')\n",
        "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
        "    cat_features = [\n",
        "        \"B_30\",\n",
        "        \"B_38\",\n",
        "        \"D_114\",\n",
        "        \"D_116\",\n",
        "        \"D_117\",\n",
        "        \"D_120\",\n",
        "        \"D_126\",\n",
        "        \"D_63\",\n",
        "        \"D_64\",\n",
        "        \"D_66\",\n",
        "        \"D_68\",\n",
        "    ]\n",
        "    num_features = [col for col in features if col not in cat_features]\n",
        "    \n",
        "    # Train FE\n",
        "    print('Starting train feature extraction')\n",
        "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n",
        "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
        "    train_num_agg.reset_index(inplace = True)\n",
        "\n",
        "    # Lag Features\n",
        "    for col in train_num_agg:\n",
        "        if 'last' in col and col.replace('last', 'first') in train_num_agg:\n",
        "            train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
        "#             train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
        "\n",
        "#     train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'first', 'last', 'nunique'])\n",
        "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['first', 'last'])\n",
        "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
        "    train_cat_agg.reset_index(inplace = True)\n",
        "    \n",
        "    train_labels = pd.read_csv('/content/train_labels.csv')\n",
        "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
        "    print('Train shape: ', train.shape)    \n",
        "    del train_num_agg, train_cat_agg\n",
        "    gc.collect()\n",
        "    \n",
        "    train.to_parquet('train_fe_plus_plus.parquet')\n",
        "    del train\n",
        "    gc.collect()\n",
        "    \n",
        "    # Test FE\n",
        "    test = pd.read_parquet('/content/test.parquet')\n",
        "    print('Starting test feature extraction')\n",
        "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n",
        "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
        "    test_num_agg.reset_index(inplace = True)\n",
        "\n",
        "    # Lag Features\n",
        "    for col in test_num_agg:\n",
        "        if 'last' in col and col.replace('last', 'first') in test_num_agg:\n",
        "            test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
        "#             test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
        "\n",
        "#     test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'first', 'last', 'nunique'])\n",
        "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['first', 'last'])\n",
        "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
        "    test_cat_agg.reset_index(inplace = True)\n",
        "    \n",
        "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID')\n",
        "    print('Test shape: ', test.shape)\n",
        "    del test_num_agg, test_cat_agg\n",
        "    gc.collect()\n",
        "    \n",
        "    \n",
        "    # Save files to disk\n",
        "    test.to_parquet('test_fe_plus_plus.parquet')\n",
        "    del test\n",
        "    gc.collect()\n",
        "    \n",
        "# Read & Preprocess Data\n",
        "# read_preprocess_data()"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 0.16385,
          "end_time": "2022-06-19T23:15:37.941388",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.777538",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%%\n"
        },
        "execution": {
          "iopub.status.busy": "2022-07-15T15:26:01.460512Z",
          "iopub.execute_input": "2022-07-15T15:26:01.461325Z",
          "iopub.status.idle": "2022-07-15T15:26:18.974098Z",
          "shell.execute_reply.started": "2022-07-15T15:26:01.461213Z",
          "shell.execute_reply": "2022-07-15T15:26:18.972602Z"
        },
        "trusted": true,
        "id": "kSC_1oNQuzlu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mv /content/train_fe_plus_plus.parquet /content/amex-fe-plus/\n",
        "# !mv /content/test_fe_plus_plus.parquet /content/amex-fe-plus/"
      ],
      "metadata": {
        "id": "7hS5QEfe3nL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !kaggle datasets init -p /content/amex-fe-plus"
      ],
      "metadata": {
        "id": "6IfjfgG657Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mv /content/dataset-metadata.json /content/amex-fe-plus/"
      ],
      "metadata": {
        "id": "P6k9WJe86tGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !kaggle datasets create -p /content/amex-fe-plus"
      ],
      "metadata": {
        "id": "dvPRC0IB4E7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training & Inference"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.002398,
          "end_time": "2022-06-19T23:15:37.946621",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.944223",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "672r-QJMuzlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d ryuina/amex-fe-plus\n",
        "!unzip /content/amex-fe-plus.zip"
      ],
      "metadata": {
        "id": "C2Kqq_4l7Am1",
        "outputId": "6b39ac87-7c34-419b-8dcd-19c7c083763d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading amex-fe-plus.zip to /content\n",
            " 99% 3.40G/3.42G [00:14<00:00, 266MB/s]\n",
            "100% 3.42G/3.42G [00:14<00:00, 260MB/s]\n",
            "Archive:  /content/amex-fe-plus.zip\n",
            "  inflating: test_fe_plus_plus.parquet  \n",
            "  inflating: train_fe_plus_plus.parquet  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Library\n",
        "# ====================================================\n",
        "import os\n",
        "import gc; gc.enable()\n",
        "import joblib\n",
        "import pickle\n",
        "import random\n",
        "import warnings\n",
        "import itertools\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "warnings.filterwarnings('ignore')\n",
        "from itertools import combinations\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_rows', 500)\n",
        "from catboost import CatBoostClassifier\n",
        "pd.set_option('display.max_columns', 500)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "\n",
        "class CFG:\n",
        "    input_dir = '/content/'\n",
        "    seed = 42\n",
        "    n_folds = 5\n",
        "    target = 'target'\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "def read_data():\n",
        "    train = pd.read_parquet(CFG.input_dir + 'train_fe_plus_plus.parquet')\n",
        "    test = pd.read_parquet(CFG.input_dir + 'test_fe_plus_plus.parquet')\n",
        "    return train, test\n",
        "\n",
        "def amex_metric(y_true, y_pred):\n",
        "    labels = np.transpose(np.array([y_true, y_pred]))\n",
        "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
        "    weights = np.where(labels[:,0]==0, 20, 1)\n",
        "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
        "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
        "    gini = [0,0]\n",
        "    for i in [1,0]:\n",
        "        labels = np.transpose(np.array([y_true, y_pred]))\n",
        "        labels = labels[labels[:, i].argsort()[::-1]]\n",
        "        weight = np.where(labels[:,0]==0, 20, 1)\n",
        "        weight_random = np.cumsum(weight / np.sum(weight))\n",
        "        total_pos = np.sum(labels[:, 0] *  weight)\n",
        "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
        "        lorentz = cum_pos_found / total_pos\n",
        "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
        "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
        "\n",
        "def amex_metric_np(preds, target):\n",
        "    indices = np.argsort(preds)[::-1]\n",
        "    preds, target = preds[indices], target[indices]\n",
        "    weight = 20.0 - target * 19.0\n",
        "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
        "    four_pct_mask = cum_norm_weight <= 0.04\n",
        "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
        "    weighted_target = target * weight\n",
        "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
        "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
        "    n_pos = np.sum(target)\n",
        "    n_neg = target.shape[0] - n_pos\n",
        "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
        "    g = gini / gini_max\n",
        "    return 0.5 * (g + d)"
      ],
      "metadata": {
        "papermill": {
          "duration": 1.91354,
          "end_time": "2022-06-19T23:15:39.862701",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.949161",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%%\n"
        },
        "execution": {
          "iopub.status.busy": "2022-07-15T15:26:18.975287Z",
          "iopub.status.idle": "2022-07-15T15:26:18.975786Z",
          "shell.execute_reply.started": "2022-07-15T15:26:18.975552Z",
          "shell.execute_reply": "2022-07-15T15:26:18.975573Z"
        },
        "trusted": true,
        "id": "15l0MOvouzlw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training LightGBM (DART) Model\n",
        "\n",
        "- Final predictions output uploaded as a public dataset. "
      ],
      "metadata": {
        "id": "64hhK5K2uzlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything(CFG.seed)\n",
        "train, test = read_data()"
      ],
      "metadata": {
        "id": "kFQsUkTpemrU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encode categorical features\n",
        "cat_features = [\n",
        "    \"B_30\",\n",
        "    \"B_38\",\n",
        "    \"D_114\",\n",
        "    \"D_116\",\n",
        "    \"D_117\",\n",
        "    \"D_120\",\n",
        "    \"D_126\",\n",
        "    \"D_63\",\n",
        "    \"D_64\",\n",
        "    \"D_66\",\n",
        "    \"D_68\"\n",
        "]\n",
        "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
        "for cat_col in cat_features:\n",
        "    encoder = LabelEncoder()\n",
        "    train[cat_col] = encoder.fit_transform(train[cat_col])\n",
        "    test[cat_col] = encoder.transform(test[cat_col])\n",
        "\n",
        "# Round last float features to 2 decimal place\n",
        "num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
        "num_cols = [col for col in num_cols if 'last' in col]\n",
        "for col in num_cols:\n",
        "    train[col + '_round2'] = train[col].round(2)\n",
        "    test[col + '_round2'] = test[col].round(2)\n",
        "\n",
        "# Get feature list\n",
        "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]"
      ],
      "metadata": {
        "id": "3apqtSQzbZG1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': \"binary_logloss\",\n",
        "    'boosting': 'dart',\n",
        "    'seed': CFG.seed,\n",
        "    'num_leaves': 100,\n",
        "    'learning_rate': 0.02,\n",
        "    'feature_fraction': 0.20,\n",
        "    'bagging_freq': 10,\n",
        "    'bagging_fraction': 0.50,\n",
        "    'n_jobs': -1,\n",
        "    'lambda_l2': 2,\n",
        "    'min_data_in_leaf': 40\n",
        "    }"
      ],
      "metadata": {
        "id": "S00nxuAZbdBP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lgb_amex_metric(y_pred, y_true):\n",
        "    y_true = y_true.get_label()\n",
        "    return 'amex_metric', amex_metric(y_true, y_pred), True\n",
        "\n",
        "def train_and_evaluate(train):\n",
        "    # Create a numpy array to store out of folds predictions\n",
        "    oof_predictions = np.zeros(len(train))\n",
        "    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
        "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
        "        print(' ')\n",
        "        print('-'*50)\n",
        "        print(f'Training fold {fold} with {len(features)} features...')\n",
        "        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
        "        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
        "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
        "        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
        "        model = lgb.train(\n",
        "            params = params,\n",
        "            train_set = lgb_train,\n",
        "            num_boost_round = 10500,\n",
        "            valid_sets = [lgb_train, lgb_valid],\n",
        "            early_stopping_rounds = 100,\n",
        "            verbose_eval = 500,\n",
        "            feval = lgb_amex_metric\n",
        "            )\n",
        "        # Save best model\n",
        "        joblib.dump(model, f'lgbm_fold{fold}_seed{CFG.seed}.pkl')\n",
        "        # Predict validation\n",
        "        val_pred = model.predict(x_val)\n",
        "        # Add to out of folds array\n",
        "        oof_predictions[val_ind] = val_pred\n",
        "\n",
        "        # Compute fold metric\n",
        "        score = amex_metric(y_val, val_pred)\n",
        "        print(f'Our fold {fold} CV score is {score}')\n",
        "        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid, model\n",
        "        gc.collect()\n",
        "    # Compute out of folds metric\n",
        "    score = amex_metric(train[CFG.target], oof_predictions)\n",
        "    print(f'Our out of folds CV score is {score}')\n",
        "    # Create a dataframe to store out of folds predictions\n",
        "    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
        "    oof_df.to_csv(f'oof_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
        "\n",
        "train_and_evaluate(train)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-07-15T15:26:18.977741Z",
          "iopub.status.idle": "2022-07-15T15:26:18.978405Z",
          "shell.execute_reply.started": "2022-07-15T15:26:18.978196Z",
          "shell.execute_reply": "2022-07-15T15:26:18.978218Z"
        },
        "trusted": true,
        "id": "9p5Z6PX7uzlx",
        "outputId": "d03f46c6-eb6b-413c-802b-6ff22ebff015",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "--------------------------------------------------\n",
            "Training fold 0 with 1447 features...\n",
            "[500]\ttraining's binary_logloss: 0.257983\ttraining's amex_metric: 0.789465\tvalid_1's binary_logloss: 0.262221\tvalid_1's amex_metric: 0.778262\n",
            "[1000]\ttraining's binary_logloss: 0.21133\ttraining's amex_metric: 0.81624\tvalid_1's binary_logloss: 0.223763\tvalid_1's amex_metric: 0.791409\n",
            "[1500]\ttraining's binary_logloss: 0.197546\ttraining's amex_metric: 0.834937\tvalid_1's binary_logloss: 0.218409\tvalid_1's amex_metric: 0.794965\n",
            "[2000]\ttraining's binary_logloss: 0.185267\ttraining's amex_metric: 0.854308\tvalid_1's binary_logloss: 0.215635\tvalid_1's amex_metric: 0.797542\n",
            "[2500]\ttraining's binary_logloss: 0.176918\ttraining's amex_metric: 0.869629\tvalid_1's binary_logloss: 0.214728\tvalid_1's amex_metric: 0.797912\n",
            "[3000]\ttraining's binary_logloss: 0.167927\ttraining's amex_metric: 0.884275\tvalid_1's binary_logloss: 0.213903\tvalid_1's amex_metric: 0.799122\n",
            "[3500]\ttraining's binary_logloss: 0.159211\ttraining's amex_metric: 0.898982\tvalid_1's binary_logloss: 0.213543\tvalid_1's amex_metric: 0.799824\n",
            "[4000]\ttraining's binary_logloss: 0.151327\ttraining's amex_metric: 0.913004\tvalid_1's binary_logloss: 0.213246\tvalid_1's amex_metric: 0.800314\n",
            "[4500]\ttraining's binary_logloss: 0.143733\ttraining's amex_metric: 0.925776\tvalid_1's binary_logloss: 0.213065\tvalid_1's amex_metric: 0.800822\n",
            "[5000]\ttraining's binary_logloss: 0.136257\ttraining's amex_metric: 0.937552\tvalid_1's binary_logloss: 0.213079\tvalid_1's amex_metric: 0.801499\n",
            "[5500]\ttraining's binary_logloss: 0.129607\ttraining's amex_metric: 0.947749\tvalid_1's binary_logloss: 0.212963\tvalid_1's amex_metric: 0.800778\n",
            "[6000]\ttraining's binary_logloss: 0.123991\ttraining's amex_metric: 0.956254\tvalid_1's binary_logloss: 0.213009\tvalid_1's amex_metric: 0.800916\n",
            "[6500]\ttraining's binary_logloss: 0.11824\ttraining's amex_metric: 0.963095\tvalid_1's binary_logloss: 0.213065\tvalid_1's amex_metric: 0.801553\n",
            "[7000]\ttraining's binary_logloss: 0.111715\ttraining's amex_metric: 0.971248\tvalid_1's binary_logloss: 0.213154\tvalid_1's amex_metric: 0.8021\n",
            "[7500]\ttraining's binary_logloss: 0.10571\ttraining's amex_metric: 0.978127\tvalid_1's binary_logloss: 0.213321\tvalid_1's amex_metric: 0.801559\n",
            "[8000]\ttraining's binary_logloss: 0.100469\ttraining's amex_metric: 0.983308\tvalid_1's binary_logloss: 0.213591\tvalid_1's amex_metric: 0.800539\n",
            "[8500]\ttraining's binary_logloss: 0.0960363\ttraining's amex_metric: 0.987222\tvalid_1's binary_logloss: 0.213812\tvalid_1's amex_metric: 0.800749\n",
            "[9000]\ttraining's binary_logloss: 0.0911781\ttraining's amex_metric: 0.990924\tvalid_1's binary_logloss: 0.214068\tvalid_1's amex_metric: 0.800456\n",
            "[9500]\ttraining's binary_logloss: 0.0869254\ttraining's amex_metric: 0.993466\tvalid_1's binary_logloss: 0.214304\tvalid_1's amex_metric: 0.800561\n",
            "[10000]\ttraining's binary_logloss: 0.0828121\ttraining's amex_metric: 0.995711\tvalid_1's binary_logloss: 0.21449\tvalid_1's amex_metric: 0.799755\n",
            "[10500]\ttraining's binary_logloss: 0.0793601\ttraining's amex_metric: 0.997005\tvalid_1's binary_logloss: 0.214835\tvalid_1's amex_metric: 0.79974\n",
            "Our fold 0 CV score is 0.7997401646760158\n",
            " \n",
            "--------------------------------------------------\n",
            "Training fold 1 with 1447 features...\n",
            "[500]\ttraining's binary_logloss: 0.257359\ttraining's amex_metric: 0.791424\tvalid_1's binary_logloss: 0.263873\tvalid_1's amex_metric: 0.772014\n",
            "[1000]\ttraining's binary_logloss: 0.21053\ttraining's amex_metric: 0.817609\tvalid_1's binary_logloss: 0.226813\tvalid_1's amex_metric: 0.782685\n",
            "[1500]\ttraining's binary_logloss: 0.196572\ttraining's amex_metric: 0.836441\tvalid_1's binary_logloss: 0.221497\tvalid_1's amex_metric: 0.787269\n",
            "[2000]\ttraining's binary_logloss: 0.184224\ttraining's amex_metric: 0.856038\tvalid_1's binary_logloss: 0.219038\tvalid_1's amex_metric: 0.78876\n",
            "[2500]\ttraining's binary_logloss: 0.175913\ttraining's amex_metric: 0.871692\tvalid_1's binary_logloss: 0.218259\tvalid_1's amex_metric: 0.78992\n",
            "[3000]\ttraining's binary_logloss: 0.166948\ttraining's amex_metric: 0.886177\tvalid_1's binary_logloss: 0.217645\tvalid_1's amex_metric: 0.791106\n",
            "[3500]\ttraining's binary_logloss: 0.158283\ttraining's amex_metric: 0.900637\tvalid_1's binary_logloss: 0.217247\tvalid_1's amex_metric: 0.791374\n",
            "[4000]\ttraining's binary_logloss: 0.150431\ttraining's amex_metric: 0.914327\tvalid_1's binary_logloss: 0.216988\tvalid_1's amex_metric: 0.791992\n",
            "[4500]\ttraining's binary_logloss: 0.142879\ttraining's amex_metric: 0.927136\tvalid_1's binary_logloss: 0.216754\tvalid_1's amex_metric: 0.792342\n",
            "[5000]\ttraining's binary_logloss: 0.135359\ttraining's amex_metric: 0.938501\tvalid_1's binary_logloss: 0.216693\tvalid_1's amex_metric: 0.792766\n",
            "[5500]\ttraining's binary_logloss: 0.128767\ttraining's amex_metric: 0.948327\tvalid_1's binary_logloss: 0.216728\tvalid_1's amex_metric: 0.793614\n",
            "[6000]\ttraining's binary_logloss: 0.123198\ttraining's amex_metric: 0.95651\tvalid_1's binary_logloss: 0.216742\tvalid_1's amex_metric: 0.792635\n",
            "[6500]\ttraining's binary_logloss: 0.117478\ttraining's amex_metric: 0.963938\tvalid_1's binary_logloss: 0.216808\tvalid_1's amex_metric: 0.792993\n",
            "[7000]\ttraining's binary_logloss: 0.111003\ttraining's amex_metric: 0.971611\tvalid_1's binary_logloss: 0.216931\tvalid_1's amex_metric: 0.793173\n",
            "[7500]\ttraining's binary_logloss: 0.105011\ttraining's amex_metric: 0.978259\tvalid_1's binary_logloss: 0.217141\tvalid_1's amex_metric: 0.792997\n",
            "[8000]\ttraining's binary_logloss: 0.0997892\ttraining's amex_metric: 0.983502\tvalid_1's binary_logloss: 0.217324\tvalid_1's amex_metric: 0.791819\n",
            "[8500]\ttraining's binary_logloss: 0.0954356\ttraining's amex_metric: 0.987507\tvalid_1's binary_logloss: 0.217388\tvalid_1's amex_metric: 0.792045\n",
            "[9000]\ttraining's binary_logloss: 0.0905755\ttraining's amex_metric: 0.99117\tvalid_1's binary_logloss: 0.217712\tvalid_1's amex_metric: 0.791813\n",
            "[9500]\ttraining's binary_logloss: 0.0863197\ttraining's amex_metric: 0.993705\tvalid_1's binary_logloss: 0.218034\tvalid_1's amex_metric: 0.791828\n",
            "[10000]\ttraining's binary_logloss: 0.0822415\ttraining's amex_metric: 0.995743\tvalid_1's binary_logloss: 0.2184\tvalid_1's amex_metric: 0.792353\n",
            "[10500]\ttraining's binary_logloss: 0.0788196\ttraining's amex_metric: 0.997069\tvalid_1's binary_logloss: 0.218678\tvalid_1's amex_metric: 0.792413\n",
            "Our fold 1 CV score is 0.7924130054472631\n",
            " \n",
            "--------------------------------------------------\n",
            "Training fold 2 with 1447 features...\n",
            "[500]\ttraining's binary_logloss: 0.257375\ttraining's amex_metric: 0.790029\tvalid_1's binary_logloss: 0.264345\tvalid_1's amex_metric: 0.775734\n",
            "[1000]\ttraining's binary_logloss: 0.210523\ttraining's amex_metric: 0.817829\tvalid_1's binary_logloss: 0.22633\tvalid_1's amex_metric: 0.788717\n",
            "[1500]\ttraining's binary_logloss: 0.19673\ttraining's amex_metric: 0.836628\tvalid_1's binary_logloss: 0.220982\tvalid_1's amex_metric: 0.792571\n",
            "[2000]\ttraining's binary_logloss: 0.184557\ttraining's amex_metric: 0.855916\tvalid_1's binary_logloss: 0.218391\tvalid_1's amex_metric: 0.794491\n",
            "[2500]\ttraining's binary_logloss: 0.176234\ttraining's amex_metric: 0.87116\tvalid_1's binary_logloss: 0.217448\tvalid_1's amex_metric: 0.796036\n",
            "[3000]\ttraining's binary_logloss: 0.167307\ttraining's amex_metric: 0.885732\tvalid_1's binary_logloss: 0.216694\tvalid_1's amex_metric: 0.796618\n",
            "[3500]\ttraining's binary_logloss: 0.158531\ttraining's amex_metric: 0.900762\tvalid_1's binary_logloss: 0.216314\tvalid_1's amex_metric: 0.795924\n",
            "[4000]\ttraining's binary_logloss: 0.150689\ttraining's amex_metric: 0.913987\tvalid_1's binary_logloss: 0.215952\tvalid_1's amex_metric: 0.796413\n",
            "[4500]\ttraining's binary_logloss: 0.14302\ttraining's amex_metric: 0.926825\tvalid_1's binary_logloss: 0.21587\tvalid_1's amex_metric: 0.795814\n",
            "[5000]\ttraining's binary_logloss: 0.135513\ttraining's amex_metric: 0.938357\tvalid_1's binary_logloss: 0.215795\tvalid_1's amex_metric: 0.796385\n",
            "[5500]\ttraining's binary_logloss: 0.128937\ttraining's amex_metric: 0.948053\tvalid_1's binary_logloss: 0.215727\tvalid_1's amex_metric: 0.796392\n",
            "[6000]\ttraining's binary_logloss: 0.123331\ttraining's amex_metric: 0.956815\tvalid_1's binary_logloss: 0.215664\tvalid_1's amex_metric: 0.79724\n",
            "[6500]\ttraining's binary_logloss: 0.117598\ttraining's amex_metric: 0.963523\tvalid_1's binary_logloss: 0.215769\tvalid_1's amex_metric: 0.798347\n",
            "[7000]\ttraining's binary_logloss: 0.111111\ttraining's amex_metric: 0.971469\tvalid_1's binary_logloss: 0.215868\tvalid_1's amex_metric: 0.797127\n",
            "[7500]\ttraining's binary_logloss: 0.105114\ttraining's amex_metric: 0.97798\tvalid_1's binary_logloss: 0.216011\tvalid_1's amex_metric: 0.797913\n",
            "[8000]\ttraining's binary_logloss: 0.0998686\ttraining's amex_metric: 0.983223\tvalid_1's binary_logloss: 0.216102\tvalid_1's amex_metric: 0.797281\n",
            "[8500]\ttraining's binary_logloss: 0.0954765\ttraining's amex_metric: 0.987249\tvalid_1's binary_logloss: 0.216342\tvalid_1's amex_metric: 0.796653\n",
            "[9000]\ttraining's binary_logloss: 0.0906244\ttraining's amex_metric: 0.991144\tvalid_1's binary_logloss: 0.216646\tvalid_1's amex_metric: 0.797323\n",
            "[9500]\ttraining's binary_logloss: 0.0863669\ttraining's amex_metric: 0.99362\tvalid_1's binary_logloss: 0.216861\tvalid_1's amex_metric: 0.797297\n",
            "[10000]\ttraining's binary_logloss: 0.0822459\ttraining's amex_metric: 0.995731\tvalid_1's binary_logloss: 0.217181\tvalid_1's amex_metric: 0.796715\n",
            "[10500]\ttraining's binary_logloss: 0.0787874\ttraining's amex_metric: 0.99712\tvalid_1's binary_logloss: 0.217457\tvalid_1's amex_metric: 0.79717\n",
            "Our fold 2 CV score is 0.7971703976837115\n",
            " \n",
            "--------------------------------------------------\n",
            "Training fold 3 with 1447 features...\n",
            "[500]\ttraining's binary_logloss: 0.256994\ttraining's amex_metric: 0.791662\tvalid_1's binary_logloss: 0.265195\tvalid_1's amex_metric: 0.769302\n",
            "[1000]\ttraining's binary_logloss: 0.210301\ttraining's amex_metric: 0.818046\tvalid_1's binary_logloss: 0.227396\tvalid_1's amex_metric: 0.78072\n",
            "[1500]\ttraining's binary_logloss: 0.196532\ttraining's amex_metric: 0.837776\tvalid_1's binary_logloss: 0.22218\tvalid_1's amex_metric: 0.785066\n",
            "[2000]\ttraining's binary_logloss: 0.184213\ttraining's amex_metric: 0.856323\tvalid_1's binary_logloss: 0.219373\tvalid_1's amex_metric: 0.788166\n",
            "[2500]\ttraining's binary_logloss: 0.17589\ttraining's amex_metric: 0.871626\tvalid_1's binary_logloss: 0.218489\tvalid_1's amex_metric: 0.789516\n",
            "[3000]\ttraining's binary_logloss: 0.166919\ttraining's amex_metric: 0.886181\tvalid_1's binary_logloss: 0.217574\tvalid_1's amex_metric: 0.790049\n",
            "[3500]\ttraining's binary_logloss: 0.158281\ttraining's amex_metric: 0.901301\tvalid_1's binary_logloss: 0.217046\tvalid_1's amex_metric: 0.791291\n",
            "[4000]\ttraining's binary_logloss: 0.150432\ttraining's amex_metric: 0.914338\tvalid_1's binary_logloss: 0.216934\tvalid_1's amex_metric: 0.791685\n",
            "[4500]\ttraining's binary_logloss: 0.142791\ttraining's amex_metric: 0.926697\tvalid_1's binary_logloss: 0.216905\tvalid_1's amex_metric: 0.791707\n",
            "[5000]\ttraining's binary_logloss: 0.135316\ttraining's amex_metric: 0.938129\tvalid_1's binary_logloss: 0.216793\tvalid_1's amex_metric: 0.792829\n",
            "[5500]\ttraining's binary_logloss: 0.128781\ttraining's amex_metric: 0.948117\tvalid_1's binary_logloss: 0.216725\tvalid_1's amex_metric: 0.792653\n",
            "[6000]\ttraining's binary_logloss: 0.123215\ttraining's amex_metric: 0.956363\tvalid_1's binary_logloss: 0.216758\tvalid_1's amex_metric: 0.791497\n",
            "[6500]\ttraining's binary_logloss: 0.117465\ttraining's amex_metric: 0.964027\tvalid_1's binary_logloss: 0.216815\tvalid_1's amex_metric: 0.791707\n",
            "[7000]\ttraining's binary_logloss: 0.110959\ttraining's amex_metric: 0.971778\tvalid_1's binary_logloss: 0.216983\tvalid_1's amex_metric: 0.791417\n",
            "[7500]\ttraining's binary_logloss: 0.104929\ttraining's amex_metric: 0.978612\tvalid_1's binary_logloss: 0.217168\tvalid_1's amex_metric: 0.790885\n",
            "[8000]\ttraining's binary_logloss: 0.0997112\ttraining's amex_metric: 0.983761\tvalid_1's binary_logloss: 0.217427\tvalid_1's amex_metric: 0.791186\n",
            "[8500]\ttraining's binary_logloss: 0.0953448\ttraining's amex_metric: 0.987695\tvalid_1's binary_logloss: 0.217589\tvalid_1's amex_metric: 0.790948\n",
            "[9000]\ttraining's binary_logloss: 0.0904993\ttraining's amex_metric: 0.991044\tvalid_1's binary_logloss: 0.217893\tvalid_1's amex_metric: 0.790914\n",
            "[9500]\ttraining's binary_logloss: 0.0862696\ttraining's amex_metric: 0.993574\tvalid_1's binary_logloss: 0.218206\tvalid_1's amex_metric: 0.790339\n",
            "[10000]\ttraining's binary_logloss: 0.0821702\ttraining's amex_metric: 0.995729\tvalid_1's binary_logloss: 0.218428\tvalid_1's amex_metric: 0.791337\n",
            "[10500]\ttraining's binary_logloss: 0.0786633\ttraining's amex_metric: 0.997073\tvalid_1's binary_logloss: 0.218636\tvalid_1's amex_metric: 0.79178\n",
            "Our fold 3 CV score is 0.7917802197310009\n",
            " \n",
            "--------------------------------------------------\n",
            "Training fold 4 with 1447 features...\n",
            "[500]\ttraining's binary_logloss: 0.257685\ttraining's amex_metric: 0.790522\tvalid_1's binary_logloss: 0.263447\tvalid_1's amex_metric: 0.774792\n",
            "[1000]\ttraining's binary_logloss: 0.211121\ttraining's amex_metric: 0.816709\tvalid_1's binary_logloss: 0.225271\tvalid_1's amex_metric: 0.785854\n",
            "[1500]\ttraining's binary_logloss: 0.19727\ttraining's amex_metric: 0.836435\tvalid_1's binary_logloss: 0.21961\tvalid_1's amex_metric: 0.790776\n",
            "[2000]\ttraining's binary_logloss: 0.184929\ttraining's amex_metric: 0.855437\tvalid_1's binary_logloss: 0.216759\tvalid_1's amex_metric: 0.793019\n",
            "[2500]\ttraining's binary_logloss: 0.176575\ttraining's amex_metric: 0.870487\tvalid_1's binary_logloss: 0.2159\tvalid_1's amex_metric: 0.795613\n",
            "[3000]\ttraining's binary_logloss: 0.167599\ttraining's amex_metric: 0.885584\tvalid_1's binary_logloss: 0.215088\tvalid_1's amex_metric: 0.795946\n",
            "[3500]\ttraining's binary_logloss: 0.158904\ttraining's amex_metric: 0.900675\tvalid_1's binary_logloss: 0.214655\tvalid_1's amex_metric: 0.79528\n",
            "[4000]\ttraining's binary_logloss: 0.151079\ttraining's amex_metric: 0.91358\tvalid_1's binary_logloss: 0.214388\tvalid_1's amex_metric: 0.795763\n",
            "[4500]\ttraining's binary_logloss: 0.143415\ttraining's amex_metric: 0.926398\tvalid_1's binary_logloss: 0.214283\tvalid_1's amex_metric: 0.795858\n",
            "[5000]\ttraining's binary_logloss: 0.135959\ttraining's amex_metric: 0.937281\tvalid_1's binary_logloss: 0.214364\tvalid_1's amex_metric: 0.795215\n",
            "[5500]\ttraining's binary_logloss: 0.129434\ttraining's amex_metric: 0.947509\tvalid_1's binary_logloss: 0.214334\tvalid_1's amex_metric: 0.795739\n",
            "[6000]\ttraining's binary_logloss: 0.12389\ttraining's amex_metric: 0.955272\tvalid_1's binary_logloss: 0.214429\tvalid_1's amex_metric: 0.795446\n",
            "[6500]\ttraining's binary_logloss: 0.118126\ttraining's amex_metric: 0.962653\tvalid_1's binary_logloss: 0.214585\tvalid_1's amex_metric: 0.795801\n",
            "[7000]\ttraining's binary_logloss: 0.111677\ttraining's amex_metric: 0.970599\tvalid_1's binary_logloss: 0.214606\tvalid_1's amex_metric: 0.794915\n",
            "[7500]\ttraining's binary_logloss: 0.105697\ttraining's amex_metric: 0.977603\tvalid_1's binary_logloss: 0.2147\tvalid_1's amex_metric: 0.795279\n",
            "[8000]\ttraining's binary_logloss: 0.100459\ttraining's amex_metric: 0.983013\tvalid_1's binary_logloss: 0.214891\tvalid_1's amex_metric: 0.794959\n",
            "[8500]\ttraining's binary_logloss: 0.0960654\ttraining's amex_metric: 0.987064\tvalid_1's binary_logloss: 0.214954\tvalid_1's amex_metric: 0.794636\n",
            "[9000]\ttraining's binary_logloss: 0.0912306\ttraining's amex_metric: 0.990791\tvalid_1's binary_logloss: 0.215255\tvalid_1's amex_metric: 0.795405\n",
            "[9500]\ttraining's binary_logloss: 0.0869661\ttraining's amex_metric: 0.993459\tvalid_1's binary_logloss: 0.21541\tvalid_1's amex_metric: 0.7964\n",
            "[10000]\ttraining's binary_logloss: 0.0828645\ttraining's amex_metric: 0.995637\tvalid_1's binary_logloss: 0.215623\tvalid_1's amex_metric: 0.79703\n",
            "[10500]\ttraining's binary_logloss: 0.0793949\ttraining's amex_metric: 0.997033\tvalid_1's binary_logloss: 0.215897\tvalid_1's amex_metric: 0.797455\n",
            "Our fold 4 CV score is 0.7974550887738545\n",
            "Our out of folds CV score is 0.7954351292644096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del train\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "id": "P2llPNqqOKTT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.018388,
          "end_time": "2022-07-15T16:48:45.862462",
          "exception": false,
          "start_time": "2022-07-15T16:48:45.844074",
          "status": "completed"
        },
        "tags": [],
        "id": "bf46dad6"
      },
      "source": [
        "# Test part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T16:48:45.901178Z",
          "iopub.status.busy": "2022-07-15T16:48:45.900848Z",
          "iopub.status.idle": "2022-07-15T16:48:45.907526Z",
          "shell.execute_reply": "2022-07-15T16:48:45.906709Z"
        },
        "papermill": {
          "duration": 0.027751,
          "end_time": "2022-07-15T16:48:45.909278",
          "exception": false,
          "start_time": "2022-07-15T16:48:45.881527",
          "status": "completed"
        },
        "tags": [],
        "id": "c28f1826"
      },
      "outputs": [],
      "source": [
        "# CALCULATE SIZE OF EACH SEPARATE TEST PART\n",
        "def get_rows(customers, test, NUM_PARTS = 4, verbose = ''):\n",
        "    chunk = len(customers)//NUM_PARTS\n",
        "    if verbose != '':\n",
        "        print(f'We will process {verbose} data as {NUM_PARTS} separate parts.')\n",
        "        print(f'There will be {chunk} customers in each part (except the last part).')\n",
        "        print('Below are number of rows in each part:')\n",
        "    rows = []\n",
        "\n",
        "    for k in range(NUM_PARTS):\n",
        "        if k==NUM_PARTS-1: cc = customers[k*chunk:]\n",
        "        else: cc = customers[k*chunk:(k+1)*chunk]\n",
        "        s = test.loc[test.customer_ID.isin(cc)].shape[0]\n",
        "        rows.append(s)\n",
        "    if verbose != '': print( rows )\n",
        "    return rows,chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T16:48:45.947705Z",
          "iopub.status.busy": "2022-07-15T16:48:45.947377Z",
          "iopub.status.idle": "2022-07-15T16:48:47.039525Z",
          "shell.execute_reply": "2022-07-15T16:48:47.038640Z"
        },
        "papermill": {
          "duration": 1.113806,
          "end_time": "2022-07-15T16:48:47.041416",
          "exception": false,
          "start_time": "2022-07-15T16:48:45.927610",
          "status": "completed"
        },
        "tags": [],
        "id": "8c7e70c5",
        "outputId": "2a8a61ec-5879-45ce-9ff0-220c02c93849",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We will process test data as 4 separate parts.\n",
            "There will be 231155 customers in each part (except the last part).\n",
            "Below are number of rows in each part:\n",
            "[231155, 231155, 231155, 231156]\n"
          ]
        }
      ],
      "source": [
        "# COMPUTE SIZE OF 4 PARTS FOR TEST DATA\n",
        "NUM_PARTS = 4\n",
        "\n",
        "customers = test[['customer_ID']].drop_duplicates().sort_index().values.flatten()\n",
        "rows,num_cust = get_rows(customers, test[['customer_ID']], NUM_PARTS = NUM_PARTS, verbose = 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T16:48:47.081924Z",
          "iopub.status.busy": "2022-07-15T16:48:47.081615Z",
          "iopub.status.idle": "2022-07-15T16:50:55.407348Z",
          "shell.execute_reply": "2022-07-15T16:50:55.406352Z"
        },
        "papermill": {
          "duration": 128.349422,
          "end_time": "2022-07-15T16:50:55.410249",
          "exception": false,
          "start_time": "2022-07-15T16:48:47.060827",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cf53fd3",
        "outputId": "bc33fbb8-9cdc-4284-aeda-23301f525e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reading test data...\n",
            "=> Test part 1 has shape (231155, 1447)\n",
            "\n",
            "Reading test data...\n",
            "=> Test part 2 has shape (231155, 1447)\n",
            "\n",
            "Reading test data...\n",
            "=> Test part 3 has shape (231155, 1447)\n",
            "\n",
            "Reading test data...\n",
            "=> Test part 4 has shape (231156, 1447)\n"
          ]
        }
      ],
      "source": [
        "# INFER TEST DATA IN PARTS\n",
        "skip_rows = 0\n",
        "skip_cust = 0\n",
        "test_preds = []\n",
        "\n",
        "for k in range(NUM_PARTS):\n",
        "    \n",
        "    # READ PART OF TEST DATA\n",
        "    print(f'\\nReading test data...')\n",
        "    test_copy = test.iloc[skip_rows:skip_rows+rows[k]].copy()\n",
        "    test_copy = test_copy.set_index('customer_ID')\n",
        "    skip_rows += rows[k]\n",
        "    print(f'=> Test part {k+1} has shape', test_copy.shape )\n",
        "    \n",
        "    # PROCESS AND FEATURE ENGINEER PART OF TEST DATA\n",
        "    if k==NUM_PARTS-1: test_copy = test_copy.loc[customers[skip_cust:]]\n",
        "    else: test_copy = test_copy.loc[customers[skip_cust:skip_cust+num_cust]]\n",
        "    skip_cust += num_cust\n",
        "        \n",
        "    # INFER XGB MODELS ON TEST DATA\n",
        "    model = joblib.load(f'lgbm_fold0_seed{CFG.seed}.pkl')\n",
        "    preds = model.predict(test_copy)\n",
        "    for f in range(1,CFG.n_folds):\n",
        "        model = joblib.load(f'lgbm_fold{f}_seed{CFG.seed}.pkl')\n",
        "        preds += model.predict(test_copy)\n",
        "    preds /= CFG.n_folds\n",
        "    test_preds.append(preds)\n",
        "\n",
        "    # CLEAN MEMORY\n",
        "    del test_copy, model\n",
        "    _ = gc.collect()\n",
        "\n",
        "del test\n",
        "_ = gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.067515,
          "end_time": "2022-07-15T16:50:55.538577",
          "exception": false,
          "start_time": "2022-07-15T16:50:55.471062",
          "status": "completed"
        },
        "tags": [],
        "id": "02259545"
      },
      "source": [
        "# Submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T16:50:55.628196Z",
          "iopub.status.busy": "2022-07-15T16:50:55.627855Z",
          "iopub.status.idle": "2022-07-15T16:51:02.864876Z",
          "shell.execute_reply": "2022-07-15T16:51:02.864114Z"
        },
        "papermill": {
          "duration": 7.268354,
          "end_time": "2022-07-15T16:51:02.866646",
          "exception": false,
          "start_time": "2022-07-15T16:50:55.598292",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "00d908fd",
        "outputId": "3c585513-a409-4429-ac2a-4de4300a38a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file shape is (924621, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         customer_ID  prediction\n",
              "0  00000469ba478561f23a92a868bd366de6f6527a684c9a...    0.015171\n",
              "1  00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...    0.000433\n",
              "2  0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...    0.033402\n",
              "3  00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...    0.244978\n",
              "4  00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...    0.900133"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f08e9ac-7652-4a4a-a484-bf0a3471e994\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_ID</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
              "      <td>0.015171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...</td>\n",
              "      <td>0.000433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...</td>\n",
              "      <td>0.033402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...</td>\n",
              "      <td>0.244978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...</td>\n",
              "      <td>0.900133</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f08e9ac-7652-4a4a-a484-bf0a3471e994')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f08e9ac-7652-4a4a-a484-bf0a3471e994 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f08e9ac-7652-4a4a-a484-bf0a3471e994');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# WRITE SUBMISSION FILE\n",
        "test = pd.DataFrame(index=customers,data={'prediction': np.concatenate(test_preds)})\n",
        "sub = pd.read_csv('sample_submission.csv')[['customer_ID']]\n",
        "sub['customer_ID_hash'] = sub['customer_ID'].copy()\n",
        "sub = sub.set_index('customer_ID_hash')\n",
        "sub = sub.merge(test[['prediction']], left_index=True, right_index=True, how='left')\n",
        "sub = sub.reset_index(drop=True)\n",
        "\n",
        "# DISPLAY PREDICTIONS\n",
        "sub.to_csv(f'submission_lgb_v1_seed{CFG.seed}_fold{CFG.n_folds}.csv',index=False)\n",
        "print('Submission file shape is', sub.shape )\n",
        "sub.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T16:51:02.918871Z",
          "iopub.status.busy": "2022-07-15T16:51:02.918494Z",
          "iopub.status.idle": "2022-07-15T16:51:03.267833Z",
          "shell.execute_reply": "2022-07-15T16:51:03.266949Z"
        },
        "papermill": {
          "duration": 0.374502,
          "end_time": "2022-07-15T16:51:03.269960",
          "exception": false,
          "start_time": "2022-07-15T16:51:02.895458",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "533e5941",
        "outputId": "f4c7670f-c91c-4e4f-ee6c-f838a8941efb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# PLOT PREDICTIONS\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sub.prediction, bins=100)\n",
        "plt.title('Test Predictions')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction\n",
        "\n",
        "- Replace / comment-out this to use your own predictions from the model in the above cell."
      ],
      "metadata": {
        "papermill": {
          "duration": 0.00263,
          "end_time": "2022-06-19T23:15:39.870669",
          "exception": false,
          "start_time": "2022-06-19T23:15:39.868039",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ofomkRituzly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit\n",
        "!kaggle competitions submit -c amex-default-prediction -f submission_lgb_v1_seed42_fold5.csv -m \"the first version. fe lag plus seed 52 fold 5 From colab\""
      ],
      "metadata": {
        "id": "A6OIgRv0CD76",
        "outputId": "c6a8ad81-d721-4725-b26a-dd79ec2cf63c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 75.4M/75.4M [00:02<00:00, 29.7MB/s]\n",
            "Successfully submitted to American Express - Default Prediction"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submissions amex-default-prediction"
      ],
      "metadata": {
        "papermill": {
          "duration": 7.116467,
          "end_time": "2022-06-19T23:15:46.98989",
          "exception": false,
          "start_time": "2022-06-19T23:15:39.873423",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%%\n"
        },
        "execution": {
          "iopub.status.busy": "2022-07-15T15:26:18.979284Z",
          "iopub.status.idle": "2022-07-15T15:26:18.979914Z",
          "shell.execute_reply.started": "2022-07-15T15:26:18.979701Z",
          "shell.execute_reply": "2022-07-15T15:26:18.979723Z"
        },
        "trusted": true,
        "id": "Ik1UoN1Auzly",
        "outputId": "66b86077-0fb1-4905-837f-584878bdaee7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fileName                            date                 description                                               status    publicScore  privateScore  \n",
            "----------------------------------  -------------------  --------------------------------------------------------  --------  -----------  ------------  \n",
            "submission_lgb_v1_seed42_fold5.csv  2022-07-18 20:37:22  the first version. fe lag plus seed 52 fold 5 From colab  complete  0.797                      \n",
            "submission_cat_v1.csv               2022-07-18 06:30:57  From colab seed 42 fold 5 lag plus                        complete  0.795                      \n",
            "Amex Default Prediction with Cat    2022-07-16 16:14:20  Notebook Amex Default Prediction with Cat | Version 125   complete  0.794                      \n",
            "Amex Default Prediction with Cat    2022-07-15 16:33:32  Notebook Amex Default Prediction with Cat | Version 127   complete  0.798                      \n",
            "Amex Default Prediction with Cat    2022-07-15 16:24:25  Notebook Amex Default Prediction with Cat | Version 126   complete  0.798                      \n",
            "submission_cat_v123_seed52_794.csv  2022-07-15 16:12:09                                                            complete  0.795                      \n",
            "submission_cat_v123_0794.csv        2022-07-15 15:47:08                                                            complete  0.795                      \n",
            "Amex Default Prediction with Cat    2022-07-15 13:53:07  Notebook Amex Default Prediction with Cat | Version 123   complete  0.798                      \n",
            "Amex Default Prediction with Cat    2022-07-12 10:17:49  Notebook Amex Default Prediction with Cat | Version 122   complete  0.794                      \n",
            "Amex Default Prediction with Cat    2022-07-11 16:41:48  Notebook Amex Default Prediction with Cat | Version 119   complete  0.794                      \n",
            "Amex Default Prediction with Cat    2022-07-11 13:00:10  Notebook Amex Default Prediction with Cat | Version 116   complete  0.794                      \n",
            "Amex Default Prediction with Cat    2022-07-10 12:29:19  Notebook Amex Default Prediction with Cat | Version 115   complete  0.798                      \n",
            "Amex Default Prediction with Cat    2022-07-10 12:26:36  Notebook Amex Default Prediction with Cat | Version 114   complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-10 07:38:14  Notebook Amex Default Prediction with Cat | Version 109   complete  0.798                      \n",
            "Amex Default Prediction with Cat    2022-07-10 07:34:41  Notebook Amex Default Prediction with Cat | Version 108   complete  0.798                      \n",
            "Amex Default Prediction with Cat    2022-07-10 07:31:41  Notebook Amex Default Prediction with Cat | Version 107   complete  0.798                      \n",
            "Amex Default Prediction with Cat    2022-07-07 16:06:53  Notebook Amex Default Prediction with Cat | Version 106   complete  0.798                      \n",
            "Amex Default Prediction with Cat    2022-07-07 16:01:41  Notebook Amex Default Prediction with Cat | Version 105   complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-07 15:55:53  Notebook Amex Default Prediction with Cat | Version 104   complete  0.798                      \n",
            "Amex Default Prediction with Cat    2022-07-07 15:52:16  Notebook Amex Default Prediction with Cat | Version 103   complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-05 15:48:47  Notebook Amex Default Prediction with Cat | Version 102   complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-05 15:46:36  Notebook Amex Default Prediction with Cat | Version 101   complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-05 15:37:48  Notebook Amex Default Prediction with Cat | Version 100   complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-05 15:33:29  Notebook Amex Default Prediction with Cat | Version 99    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-05 15:29:38  Notebook Amex Default Prediction with Cat | Version 98    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-04 16:21:46  Notebook Amex Default Prediction with Cat | Version 97    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-04 16:09:39  Notebook Amex Default Prediction with Cat | Version 95    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-04 14:45:39  Notebook Amex Default Prediction with Cat | Version 93    complete  0.797                      \n",
            "Amex Default Prediction - XGBoost   2022-07-04 14:01:00  Notebook Amex Default Prediction - XGBoost | Version 25   complete  0.793                      \n",
            "Amex Default Prediction - XGBoost   2022-07-04 13:34:15  Notebook Amex Default Prediction - XGBoost | Version 24   complete  0.794                      \n",
            "Amex Default Prediction with Cat    2022-07-03 11:56:30  Notebook Amex Default Prediction with Cat | Version 86    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-03 11:17:11  Notebook Amex Default Prediction with Cat | Version 85    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-03 05:11:36  Notebook Amex Default Prediction with Cat | Version 84    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-03 04:59:28  Notebook Amex Default Prediction with Cat | Version 83    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-03 04:22:26  Notebook Amex Default Prediction with Cat | Version 82    complete  0.792                      \n",
            "Amex Default Prediction with Cat    2022-07-02 16:13:03  Notebook Amex Default Prediction with Cat | Version 81    complete  0.796                      \n",
            "Amex Default Prediction with Cat    2022-07-02 15:56:06  Notebook Amex Default Prediction with Cat | Version 80    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-02 14:22:57  Notebook Amex Default Prediction with Cat | Version 79    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-02 14:17:53  Notebook Amex Default Prediction with Cat | Version 78    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-02 13:35:04  Notebook Amex Default Prediction with Cat | Version 77    complete  0.794                      \n",
            "Amex Default Prediction with Cat    2022-07-01 17:11:02  Notebook Amex Default Prediction with Cat | Version 76    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-01 17:09:06  Notebook Amex Default Prediction with Cat | Version 75    complete  0.794                      \n",
            "Amex Default Prediction with Cat    2022-07-01 15:31:01  Notebook Amex Default Prediction with Cat | Version 74    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-07-01 15:29:31  Notebook Amex Default Prediction with Cat | Version 73    complete  0.797                      \n",
            "TensorFlow GRU Starter - [0.790]    2022-07-01 15:25:26  Notebook TensorFlow GRU Starter - [0.790] | Version 3     complete  0.783                      \n",
            "Amex Default Prediction with Cat    2022-06-30 12:11:53  Notebook Amex Default Prediction with Cat | Version 72    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-06-30 12:08:27  Notebook Amex Default Prediction with Cat | Version 71    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-06-29 13:52:23  Notebook Amex Default Prediction with Cat | Version 70    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-06-29 13:49:46  Notebook Amex Default Prediction with Cat | Version 69    complete  0.797                      \n",
            "Amex Default Prediction with Cat    2022-06-29 13:43:28  Notebook Amex Default Prediction with Cat | Version 68    complete  0.797                      \n"
          ]
        }
      ]
    }
  ]
}