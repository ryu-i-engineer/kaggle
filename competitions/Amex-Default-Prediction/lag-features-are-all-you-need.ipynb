{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "lag-features-are-all-you-need.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lag Features Are All You Need\n",
        "\n",
        "> **Credits:** Based on [this](https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7963) amazing notebook.\n",
        "\n",
        "OK. Maybe not **all** you need.\n",
        "<br>\n",
        "But they improve `LightGBM`!\n",
        "_____\n",
        "\n",
        "\n",
        "This notebook stated as an ensemble of `LightGBM` + `Catboost` + `XGB` but while running it I discovered an interestin idea that worked really well.\n",
        "\n",
        "### Lag Features\n",
        "\n",
        "On this competition we get information about clients of AMEX over time. \n",
        "Most high scoring notebooks on this competiion focused on aggregating the information per client and create a single row of extracted features: One for each client.\n",
        "\n",
        "**One of such agg function is `last`**.\n",
        "\n",
        "Quick examination revealed that the `last` feature is extreamly powerful at predicting if the client defaults or not (well.. make sense..). \n",
        "So I took this two steps further: \n",
        "\n",
        "- **First feature:** Just like the `last` feature: I added a `first` feature. \n",
        "- **\"Lag\" fearures:** to capture the change over time about each client I calculated two features for every `first`, `last` pair:\n",
        "     - **Last - First:** The change since we first see the client to the last time we see the client.\n",
        "     - **Last / First:** The fractional difference since we first see the client to the last time we see the client.\n",
        "\n",
        "This improved my `LightGBM` model to the point that it overtook the whole `LightGBM` + `Catboost` + `XGB` ensemble.\n",
        "\n",
        "I uploaded a dataset containing the extracted lag features and updated the final model predictions (only `LightGBM` this time) for everyone to play with. \n",
        "\n",
        "<br>\n",
        "\n",
        "_____\n",
        "\n",
        "**Next Experiement (currently running):** More \"lag features\" variations - Also take in consideration other indices of the time-series. will keep you updated.\n",
        "_____\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.003629,
          "end_time": "2022-06-19T23:15:37.769935",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.766306",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Ta6oxF1uuzlq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing for colab"
      ],
      "metadata": {
        "id": "whFMYLB1u7rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "MwbPTJbLu1oU",
        "outputId": "6566c26b-78e3-4bb8-c4bd-7037ec0d3b76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.0.6-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.6.15)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Lx3ZHpcHvLK0",
        "outputId": "397c18b7-a108-408c-8785-4417c5650783",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4dc282da-713e-4954-8a69-7d97174e75cd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4dc282da-713e-4954-8a69-7d97174e75cd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 62 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c amex-default-prediction -f sample_submission.csv\n",
        "!unzip /content/sample_submission.csv.zip"
      ],
      "metadata": {
        "id": "jeIvlVN0vQ08",
        "outputId": "d27f2ac6-dc68-41e1-efbd-1935d3ce130d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading sample_submission.csv.zip to /content\n",
            " 77% 25.0M/32.4M [00:00<00:00, 89.6MB/s]\n",
            "100% 32.4M/32.4M [00:00<00:00, 107MB/s] \n",
            "Archive:  /content/sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c amex-default-prediction -f train_labels.csv\n",
        "!unzip /content/train_labels.csv.zip"
      ],
      "metadata": {
        "id": "PfGNoPMDxoPk",
        "outputId": "614cae64-48bb-49e9-baf5-8ebae27acc71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading train_labels.csv.zip to /content\n",
            "\r  0% 0.00/16.2M [00:00<?, ?B/s]\r 62% 10.0M/16.2M [00:00<00:00, 105MB/s]\n",
            "\r100% 16.2M/16.2M [00:00<00:00, 138MB/s]\n",
            "Archive:  /content/train_labels.csv.zip\n",
            "  inflating: train_labels.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d raddar/amex-data-integer-dtypes-parquet-format\n",
        "!unzip /content/amex-data-integer-dtypes-parquet-format.zip"
      ],
      "metadata": {
        "id": "q8p7BzCIvSAK",
        "outputId": "e66349c1-bb4b-465e-e34f-257be5d768e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amex-data-integer-dtypes-parquet-format.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  /content/amex-data-integer-dtypes-parquet-format.zip\n",
            "replace test.parquet? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace test.parquet? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace test.parquet? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: test.parquet            A\n",
            "A\n",
            "\n",
            "  inflating: train.parquet           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.002235,
          "end_time": "2022-06-19T23:15:37.774992",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.772757",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "-p0d_9druzlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Library\n",
        "# ====================================================\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "from tqdm.auto import tqdm\n",
        "import itertools\n",
        "\n",
        "# ====================================================\n",
        "# Read & preprocess data and save it to disk\n",
        "# ====================================================\n",
        "def read_preprocess_data():\n",
        "    train = pd.read_parquet('/content/train.parquet')\n",
        "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
        "    cat_features = [\n",
        "        \"B_30\",\n",
        "        \"B_38\",\n",
        "        \"D_114\",\n",
        "        \"D_116\",\n",
        "        \"D_117\",\n",
        "        \"D_120\",\n",
        "        \"D_126\",\n",
        "        \"D_63\",\n",
        "        \"D_64\",\n",
        "        \"D_66\",\n",
        "        \"D_68\",\n",
        "    ]\n",
        "    num_features = [col for col in features if col not in cat_features]\n",
        "    \n",
        "    # Train FE\n",
        "    print('Starting train feature extraction')\n",
        "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n",
        "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
        "    train_num_agg.reset_index(inplace = True)\n",
        "\n",
        "    # Lag Features\n",
        "    for col in train_num_agg:\n",
        "        if 'last' in col and col.replace('last', 'first') in train_num_agg:\n",
        "            train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
        "#             train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
        "\n",
        "#     train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'first', 'last', 'nunique'])\n",
        "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['first', 'last'])\n",
        "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
        "    train_cat_agg.reset_index(inplace = True)\n",
        "    \n",
        "    train_labels = pd.read_csv('/content/train_labels.csv')\n",
        "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
        "    print('Train shape: ', train.shape)    \n",
        "    del train_num_agg, train_cat_agg\n",
        "    gc.collect()\n",
        "    \n",
        "    train.to_parquet('train_fe_plus_plus.parquet')\n",
        "    del train\n",
        "    gc.collect()\n",
        "    \n",
        "    # Test FE\n",
        "    test = pd.read_parquet('/content/test.parquet')\n",
        "    print('Starting test feature extraction')\n",
        "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n",
        "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
        "    test_num_agg.reset_index(inplace = True)\n",
        "\n",
        "    # Lag Features\n",
        "    for col in test_num_agg:\n",
        "        if 'last' in col and col.replace('last', 'first') in test_num_agg:\n",
        "            test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
        "#             test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
        "\n",
        "#     test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'first', 'last', 'nunique'])\n",
        "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['first', 'last'])\n",
        "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
        "    test_cat_agg.reset_index(inplace = True)\n",
        "    \n",
        "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID')\n",
        "    print('Test shape: ', test.shape)\n",
        "    del test_num_agg, test_cat_agg\n",
        "    gc.collect()\n",
        "    \n",
        "    \n",
        "    # Save files to disk\n",
        "    test.to_parquet('test_fe_plus_plus.parquet')\n",
        "    del test\n",
        "    gc.collect()\n",
        "    \n",
        "# Read & Preprocess Data\n",
        "# read_preprocess_data()"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 0.16385,
          "end_time": "2022-06-19T23:15:37.941388",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.777538",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%%\n"
        },
        "execution": {
          "iopub.status.busy": "2022-07-15T15:26:01.460512Z",
          "iopub.execute_input": "2022-07-15T15:26:01.461325Z",
          "iopub.status.idle": "2022-07-15T15:26:18.974098Z",
          "shell.execute_reply.started": "2022-07-15T15:26:01.461213Z",
          "shell.execute_reply": "2022-07-15T15:26:18.972602Z"
        },
        "trusted": true,
        "id": "kSC_1oNQuzlu",
        "outputId": "0a5020b0-b91f-44ae-d72c-ae204f8b6f47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting train feature extraction\n",
            "Train shape:  (458913, 1263)\n",
            "Starting test feature extraction\n",
            "Test shape:  (924621, 1262)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mv /content/train_fe_plus_plus.parquet /content/amex-fe-plus/\n",
        "# !mv /content/test_fe_plus_plus.parquet /content/amex-fe-plus/"
      ],
      "metadata": {
        "id": "7hS5QEfe3nL-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !kaggle datasets init -p /content/amex-fe-plus"
      ],
      "metadata": {
        "id": "6IfjfgG657Oa",
        "outputId": "4b6cef91-5748-4ab6-a63d-d6db27b5dda9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data package template written to: /content/amex-fe-plus/dataset-metadata.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mv /content/dataset-metadata.json /content/amex-fe-plus/"
      ],
      "metadata": {
        "id": "P6k9WJe86tGH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !kaggle datasets create -p /content/amex-fe-plus"
      ],
      "metadata": {
        "id": "dvPRC0IB4E7Z",
        "outputId": "838aea24-55f5-4918-d8c0-c6dc98b13ba1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping folder: .ipynb_checkpoints; use '--dir-mode' to upload folders\n",
            "Starting upload for file test_fe_plus_plus.parquet\n",
            "100% 2.45G/2.45G [00:27<00:00, 96.0MB/s]\n",
            "Upload successful: test_fe_plus_plus.parquet (2GB)\n",
            "Starting upload for file train_fe_plus_plus.parquet\n",
            "100% 1.34G/1.34G [00:20<00:00, 70.4MB/s]\n",
            "Upload successful: train_fe_plus_plus.parquet (1GB)\n",
            "Your private Dataset is being created. Please check progress at https://www.kaggle.com/datasets/ryuina/amex-fe-plus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training & Inference"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.002398,
          "end_time": "2022-06-19T23:15:37.946621",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.944223",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "672r-QJMuzlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d ryuina/amex-fe-plus\n",
        "!unzip /content/amex-fe-plus.zip"
      ],
      "metadata": {
        "id": "C2Kqq_4l7Am1",
        "outputId": "d9893b5b-f830-481f-aa8e-aba2dcf10740",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading amex-fe-plus.zip to /content\n",
            "100% 3.42G/3.42G [00:19<00:00, 201MB/s]\n",
            "100% 3.42G/3.42G [00:19<00:00, 192MB/s]\n",
            "Archive:  /content/amex-fe-plus.zip\n",
            "  inflating: test_fe_plus_plus.parquet  \n",
            "  inflating: train_fe_plus_plus.parquet  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Library\n",
        "# ====================================================\n",
        "import os\n",
        "import gc\n",
        "import joblib\n",
        "import random\n",
        "import warnings\n",
        "import itertools\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "warnings.filterwarnings('ignore')\n",
        "from itertools import combinations\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_rows', 500)\n",
        "from catboost import CatBoostClassifier\n",
        "pd.set_option('display.max_columns', 500)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "\n",
        "class CFG:\n",
        "    input_dir = '/content/amex-fe-plus/'\n",
        "    seed = 42\n",
        "    n_folds = 5\n",
        "    target = 'target'\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "def read_data():\n",
        "    train = pd.read_parquet(CFG.input_dir + 'train_fe_plus_plus.parquet')\n",
        "    test = pd.read_parquet(CFG.input_dir + 'test_fe_plus_plus.parquet')\n",
        "    return train, test\n",
        "\n",
        "def amex_metric(y_true, y_pred):\n",
        "    labels = np.transpose(np.array([y_true, y_pred]))\n",
        "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
        "    weights = np.where(labels[:,0]==0, 20, 1)\n",
        "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
        "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
        "    gini = [0,0]\n",
        "    for i in [1,0]:\n",
        "        labels = np.transpose(np.array([y_true, y_pred]))\n",
        "        labels = labels[labels[:, i].argsort()[::-1]]\n",
        "        weight = np.where(labels[:,0]==0, 20, 1)\n",
        "        weight_random = np.cumsum(weight / np.sum(weight))\n",
        "        total_pos = np.sum(labels[:, 0] *  weight)\n",
        "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
        "        lorentz = cum_pos_found / total_pos\n",
        "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
        "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
        "\n",
        "def amex_metric_np(preds, target):\n",
        "    indices = np.argsort(preds)[::-1]\n",
        "    preds, target = preds[indices], target[indices]\n",
        "    weight = 20.0 - target * 19.0\n",
        "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
        "    four_pct_mask = cum_norm_weight <= 0.04\n",
        "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
        "    weighted_target = target * weight\n",
        "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
        "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
        "    n_pos = np.sum(target)\n",
        "    n_neg = target.shape[0] - n_pos\n",
        "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
        "    g = gini / gini_max\n",
        "    return 0.5 * (g + d)"
      ],
      "metadata": {
        "papermill": {
          "duration": 1.91354,
          "end_time": "2022-06-19T23:15:39.862701",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.949161",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%%\n"
        },
        "execution": {
          "iopub.status.busy": "2022-07-15T15:26:18.975287Z",
          "iopub.status.idle": "2022-07-15T15:26:18.975786Z",
          "shell.execute_reply.started": "2022-07-15T15:26:18.975552Z",
          "shell.execute_reply": "2022-07-15T15:26:18.975573Z"
        },
        "trusted": true,
        "id": "15l0MOvouzlw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training LightGBM (DART) Model\n",
        "\n",
        "- Final predictions output uploaded as a public dataset. "
      ],
      "metadata": {
        "id": "64hhK5K2uzlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lgb_amex_metric(y_pred, y_true):\n",
        "    y_true = y_true.get_label()\n",
        "    return 'amex_metric', amex_metric(y_true, y_pred), True\n",
        "\n",
        "def train_and_evaluate(train, test):\n",
        "    # Label encode categorical features\n",
        "    cat_features = [\n",
        "        \"B_30\",\n",
        "        \"B_38\",\n",
        "        \"D_114\",\n",
        "        \"D_116\",\n",
        "        \"D_117\",\n",
        "        \"D_120\",\n",
        "        \"D_126\",\n",
        "        \"D_63\",\n",
        "        \"D_64\",\n",
        "        \"D_66\",\n",
        "        \"D_68\"\n",
        "    ]\n",
        "    cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
        "    for cat_col in cat_features:\n",
        "        encoder = LabelEncoder()\n",
        "        train[cat_col] = encoder.fit_transform(train[cat_col])\n",
        "        test[cat_col] = encoder.transform(test[cat_col])\n",
        "    # Round last float features to 2 decimal place\n",
        "    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
        "    num_cols = [col for col in num_cols if 'last' in col]\n",
        "    for col in num_cols:\n",
        "        train[col + '_round2'] = train[col].round(2)\n",
        "        test[col + '_round2'] = test[col].round(2)\n",
        "    # Get feature list\n",
        "    features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': \"binary_logloss\",\n",
        "        'boosting': 'dart',\n",
        "        'seed': CFG.seed,\n",
        "        'num_leaves': 100,\n",
        "        'learning_rate': 0.02,\n",
        "        'feature_fraction': 0.20,\n",
        "        'bagging_freq': 10,\n",
        "        'bagging_fraction': 0.50,\n",
        "        'n_jobs': -1,\n",
        "        'lambda_l2': 2,\n",
        "        'min_data_in_leaf': 40\n",
        "        }\n",
        "    # Create a numpy array to store test predictions\n",
        "    test_predictions = np.zeros(len(test))\n",
        "    # Create a numpy array to store out of folds predictions\n",
        "    oof_predictions = np.zeros(len(train))\n",
        "    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
        "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
        "        print(' ')\n",
        "        print('-'*50)\n",
        "        print(f'Training fold {fold} with {len(features)} features...')\n",
        "        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
        "        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
        "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
        "        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
        "        model = lgb.train(\n",
        "            params = params,\n",
        "            train_set = lgb_train,\n",
        "            num_boost_round = 10500,\n",
        "            valid_sets = [lgb_train, lgb_valid],\n",
        "            early_stopping_rounds = 100,\n",
        "            verbose_eval = 500,\n",
        "            feval = lgb_amex_metric\n",
        "            )\n",
        "        # Save best model\n",
        "        joblib.dump(model, f'lgbm_fold{fold}_seed{CFG.seed}.pkl')\n",
        "        # Predict validation\n",
        "        val_pred = model.predict(x_val)\n",
        "        # Add to out of folds array\n",
        "        oof_predictions[val_ind] = val_pred\n",
        "        # Predict the test set\n",
        "        test_pred = model.predict(test[features])\n",
        "        test_predictions += test_pred / CFG.n_folds\n",
        "        # Compute fold metric\n",
        "        score = amex_metric(y_val, val_pred)\n",
        "        print(f'Our fold {fold} CV score is {score}')\n",
        "        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
        "        gc.collect()\n",
        "    # Compute out of folds metric\n",
        "    score = amex_metric(train[CFG.target], oof_predictions)\n",
        "    print(f'Our out of folds CV score is {score}')\n",
        "    # Create a dataframe to store out of folds predictions\n",
        "    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
        "    oof_df.to_csv(f'oof_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
        "    # Create a dataframe to store test prediction\n",
        "    test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
        "    test_df.to_csv(f'test_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
        "\n",
        "seed_everything(CFG.seed)\n",
        "train, test = read_data()\n",
        "train_and_evaluate(train, test)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-07-15T15:26:18.977741Z",
          "iopub.status.idle": "2022-07-15T15:26:18.978405Z",
          "shell.execute_reply.started": "2022-07-15T15:26:18.978196Z",
          "shell.execute_reply": "2022-07-15T15:26:18.978218Z"
        },
        "trusted": true,
        "id": "9p5Z6PX7uzlx",
        "outputId": "e739f107-8eda-4bff-84fd-a1e682faec91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "--------------------------------------------------\n",
            "Training fold 0 with 1447 features...\n",
            "[500]\ttraining's binary_logloss: 0.257983\ttraining's amex_metric: 0.789465\tvalid_1's binary_logloss: 0.262221\tvalid_1's amex_metric: 0.778262\n",
            "[1000]\ttraining's binary_logloss: 0.21133\ttraining's amex_metric: 0.81624\tvalid_1's binary_logloss: 0.223763\tvalid_1's amex_metric: 0.791409\n",
            "[1500]\ttraining's binary_logloss: 0.197546\ttraining's amex_metric: 0.834937\tvalid_1's binary_logloss: 0.218409\tvalid_1's amex_metric: 0.794965\n",
            "[2000]\ttraining's binary_logloss: 0.185267\ttraining's amex_metric: 0.854308\tvalid_1's binary_logloss: 0.215635\tvalid_1's amex_metric: 0.797542\n",
            "[2500]\ttraining's binary_logloss: 0.176918\ttraining's amex_metric: 0.869629\tvalid_1's binary_logloss: 0.214728\tvalid_1's amex_metric: 0.797912\n",
            "[3000]\ttraining's binary_logloss: 0.167927\ttraining's amex_metric: 0.884275\tvalid_1's binary_logloss: 0.213903\tvalid_1's amex_metric: 0.799122\n",
            "[3500]\ttraining's binary_logloss: 0.159211\ttraining's amex_metric: 0.898982\tvalid_1's binary_logloss: 0.213543\tvalid_1's amex_metric: 0.799824\n",
            "[4000]\ttraining's binary_logloss: 0.151327\ttraining's amex_metric: 0.913004\tvalid_1's binary_logloss: 0.213246\tvalid_1's amex_metric: 0.800314\n",
            "[4500]\ttraining's binary_logloss: 0.143733\ttraining's amex_metric: 0.925776\tvalid_1's binary_logloss: 0.213065\tvalid_1's amex_metric: 0.800822\n",
            "[5000]\ttraining's binary_logloss: 0.136257\ttraining's amex_metric: 0.937552\tvalid_1's binary_logloss: 0.213079\tvalid_1's amex_metric: 0.801499\n",
            "[5500]\ttraining's binary_logloss: 0.129607\ttraining's amex_metric: 0.947749\tvalid_1's binary_logloss: 0.212963\tvalid_1's amex_metric: 0.800778\n",
            "[6000]\ttraining's binary_logloss: 0.123991\ttraining's amex_metric: 0.956254\tvalid_1's binary_logloss: 0.213009\tvalid_1's amex_metric: 0.800916\n",
            "[6500]\ttraining's binary_logloss: 0.11824\ttraining's amex_metric: 0.963095\tvalid_1's binary_logloss: 0.213065\tvalid_1's amex_metric: 0.801553\n",
            "[7000]\ttraining's binary_logloss: 0.111715\ttraining's amex_metric: 0.971248\tvalid_1's binary_logloss: 0.213154\tvalid_1's amex_metric: 0.8021\n",
            "[7500]\ttraining's binary_logloss: 0.10571\ttraining's amex_metric: 0.978127\tvalid_1's binary_logloss: 0.213321\tvalid_1's amex_metric: 0.801559\n",
            "[8000]\ttraining's binary_logloss: 0.100469\ttraining's amex_metric: 0.983308\tvalid_1's binary_logloss: 0.213591\tvalid_1's amex_metric: 0.800539\n",
            "[8500]\ttraining's binary_logloss: 0.0960363\ttraining's amex_metric: 0.987222\tvalid_1's binary_logloss: 0.213812\tvalid_1's amex_metric: 0.800749\n",
            "[9000]\ttraining's binary_logloss: 0.0911781\ttraining's amex_metric: 0.990924\tvalid_1's binary_logloss: 0.214068\tvalid_1's amex_metric: 0.800456\n",
            "[9500]\ttraining's binary_logloss: 0.0869254\ttraining's amex_metric: 0.993466\tvalid_1's binary_logloss: 0.214304\tvalid_1's amex_metric: 0.800561\n",
            "[10000]\ttraining's binary_logloss: 0.0828121\ttraining's amex_metric: 0.995711\tvalid_1's binary_logloss: 0.21449\tvalid_1's amex_metric: 0.799755\n",
            "[10500]\ttraining's binary_logloss: 0.0793601\ttraining's amex_metric: 0.997005\tvalid_1's binary_logloss: 0.214835\tvalid_1's amex_metric: 0.79974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "id": "P2llPNqqOKTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction\n",
        "\n",
        "- Replace / comment-out this to use your own predictions from the model in the above cell."
      ],
      "metadata": {
        "papermill": {
          "duration": 0.00263,
          "end_time": "2022-06-19T23:15:39.870669",
          "exception": false,
          "start_time": "2022-06-19T23:15:39.868039",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ofomkRituzly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit\n",
        "!kaggle competitions submit -c amex-default-prediction -f submission_lgbm_v1_seed42_fold5.csv -m \"From colab\""
      ],
      "metadata": {
        "id": "A6OIgRv0CD76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "df_1 = pd.read_csv('/content/amex-predictions/test_lgbm_baseline_5fold_seed42.csv')\n",
        "df_1.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "papermill": {
          "duration": 7.116467,
          "end_time": "2022-06-19T23:15:46.98989",
          "exception": false,
          "start_time": "2022-06-19T23:15:39.873423",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%%\n"
        },
        "execution": {
          "iopub.status.busy": "2022-07-15T15:26:18.979284Z",
          "iopub.status.idle": "2022-07-15T15:26:18.979914Z",
          "shell.execute_reply.started": "2022-07-15T15:26:18.979701Z",
          "shell.execute_reply": "2022-07-15T15:26:18.979723Z"
        },
        "trusted": true,
        "id": "Ik1UoN1Auzly"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}