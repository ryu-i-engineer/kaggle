{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "lag-features-are-all-you-need.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing for colab"
      ],
      "metadata": {
        "id": "whFMYLB1u7rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "MwbPTJbLu1oU",
        "outputId": "330ef6a2-6a8d-4add-fa3d-8200d0f06b2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.6.15)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && cp /content/drive/MyDrive/backups/kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Lx3ZHpcHvLK0",
        "outputId": "f87dbca1-bc62-4e24-ec5d-af7c6b92bfdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c amex-default-prediction -f sample_submission.csv\n",
        "!unzip /content/sample_submission.csv.zip"
      ],
      "metadata": {
        "id": "jeIvlVN0vQ08",
        "outputId": "4438e7a3-5580-468e-b372-ccdf09e610ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading sample_submission.csv.zip to /content\n",
            " 28% 9.00M/32.4M [00:00<00:00, 68.5MB/s]\n",
            "100% 32.4M/32.4M [00:00<00:00, 161MB/s] \n",
            "Archive:  /content/sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c amex-default-prediction -f train_labels.csv\n",
        "!unzip /content/train_labels.csv.zip"
      ],
      "metadata": {
        "id": "PfGNoPMDxoPk",
        "outputId": "db5766c3-0a7f-45a3-da26-1807a3aff4d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading train_labels.csv.zip to /content\n",
            "\r  0% 0.00/16.2M [00:00<?, ?B/s]\r 37% 6.00M/16.2M [00:00<00:00, 62.4MB/s]\n",
            "\r100% 16.2M/16.2M [00:00<00:00, 130MB/s] \n",
            "Archive:  /content/train_labels.csv.zip\n",
            "  inflating: train_labels.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training & Inference"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.002398,
          "end_time": "2022-06-19T23:15:37.946621",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.944223",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "672r-QJMuzlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d ryuina/amex-fe-plus3\n",
        "!unzip /content/amex-fe-plus3.zip"
      ],
      "metadata": {
        "id": "C2Kqq_4l7Am1",
        "outputId": "8aaac869-6b80-42a5-de41-73a6a46d8261",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading amex-fe-plus3.zip to /content\n",
            "100% 3.20G/3.21G [00:21<00:00, 106MB/s] \n",
            "100% 3.21G/3.21G [00:21<00:00, 160MB/s]\n",
            "Archive:  /content/amex-fe-plus3.zip\n",
            "  inflating: test_fe_plus_plus.parquet  \n",
            "  inflating: train_fe_plus_plus.parquet  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Library\n",
        "# ====================================================\n",
        "import os\n",
        "import gc; gc.enable()\n",
        "import joblib\n",
        "import pickle\n",
        "import random\n",
        "import warnings\n",
        "import itertools\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "warnings.filterwarnings('ignore')\n",
        "from itertools import combinations\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "\n",
        "class CFG:\n",
        "    input_dir = '/content/'\n",
        "    seed = 42\n",
        "    n_folds = 5\n",
        "    target = 'target'\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "def read_data():\n",
        "    train = pd.read_parquet(CFG.input_dir + 'train_fe_plus_plus.parquet')\n",
        "    test = pd.read_parquet(CFG.input_dir + 'test_fe_plus_plus.parquet')\n",
        "    return train, test\n",
        "\n",
        "def amex_metric(y_true, y_pred):\n",
        "    labels = np.transpose(np.array([y_true, y_pred]))\n",
        "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
        "    weights = np.where(labels[:,0]==0, 20, 1)\n",
        "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
        "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
        "    gini = [0,0]\n",
        "    for i in [1,0]:\n",
        "        labels = np.transpose(np.array([y_true, y_pred]))\n",
        "        labels = labels[labels[:, i].argsort()[::-1]]\n",
        "        weight = np.where(labels[:,0]==0, 20, 1)\n",
        "        weight_random = np.cumsum(weight / np.sum(weight))\n",
        "        total_pos = np.sum(labels[:, 0] *  weight)\n",
        "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
        "        lorentz = cum_pos_found / total_pos\n",
        "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
        "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
        "\n",
        "def amex_metric_np(preds, target):\n",
        "    indices = np.argsort(preds)[::-1]\n",
        "    preds, target = preds[indices], target[indices]\n",
        "    weight = 20.0 - target * 19.0\n",
        "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
        "    four_pct_mask = cum_norm_weight <= 0.04\n",
        "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
        "    weighted_target = target * weight\n",
        "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
        "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
        "    n_pos = np.sum(target)\n",
        "    n_neg = target.shape[0] - n_pos\n",
        "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
        "    g = gini / gini_max\n",
        "    return 0.5 * (g + d)"
      ],
      "metadata": {
        "papermill": {
          "duration": 1.91354,
          "end_time": "2022-06-19T23:15:39.862701",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.949161",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%%\n"
        },
        "execution": {
          "iopub.status.busy": "2022-07-15T15:26:18.975287Z",
          "iopub.status.idle": "2022-07-15T15:26:18.975786Z",
          "shell.execute_reply.started": "2022-07-15T15:26:18.975552Z",
          "shell.execute_reply": "2022-07-15T15:26:18.975573Z"
        },
        "trusted": true,
        "id": "15l0MOvouzlw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training LightGBM (DART) Model\n",
        "\n",
        "- Final predictions output uploaded as a public dataset. "
      ],
      "metadata": {
        "id": "64hhK5K2uzlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything(CFG.seed)\n",
        "train, test = read_data()"
      ],
      "metadata": {
        "id": "kFQsUkTpemrU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encode categorical features\n",
        "cat_features = [\n",
        "    \"B_30\",\n",
        "    \"B_38\",\n",
        "    \"D_114\",\n",
        "    \"D_116\",\n",
        "    \"D_117\",\n",
        "    \"D_120\",\n",
        "    \"D_126\",\n",
        "    \"D_63\",\n",
        "    \"D_64\",\n",
        "    \"D_66\",\n",
        "    \"D_68\"\n",
        "]\n",
        "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
        "for cat_col in cat_features:\n",
        "    encoder = LabelEncoder()\n",
        "    train[cat_col] = encoder.fit_transform(train[cat_col])\n",
        "    test[cat_col] = encoder.transform(test[cat_col])\n",
        "\n",
        "# Round last float features to 2 decimal place\n",
        "num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
        "num_cols = [col for col in num_cols if 'last' in col]\n",
        "for col in num_cols:\n",
        "    train[col + '_round2'] = train[col].round(2)\n",
        "    test[col + '_round2'] = test[col].round(2)\n",
        "\n",
        "num_cols = [col for col in train.columns if 'last' in col]\n",
        "num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n",
        "for col in num_cols:\n",
        "    try:\n",
        "        # train[f'{col}_max-last'] = train[f'{col}_max'] - train[f'{col}_last']\n",
        "        # test[f'{col}_max-last'] = test[f'{col}_max'] - test[f'{col}_last']\n",
        "\n",
        "        # train[f'{col}_mean_min'] = train[f'{col}mean'] - train[f'{col}_min']\n",
        "        # test[f'{col}_mean_min'] = test[f'{col}_mean'] - test[f'{col}_min']\n",
        "\n",
        "        train[f'{col}_last_mean'] = train[f'{col}_last'] - train[f'{col}_mean']\n",
        "        test[f'{col}_last_mean'] = test[f'{col}_last'] - test[f'{col}_mean']\n",
        "\n",
        "        # train[f'{col}_last_mean_div'] = train[f'{col}_last'] / train[f'{col}_mean']\n",
        "        # test[f'{col}_last_mean_div'] = test[f'{col}_last'] / test[f'{col}_mean']\n",
        "    except: pass\n",
        "\n",
        "num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
        "for col in tqdm(num_cols):\n",
        "    train[col] = train[col].astype(np.float16)\n",
        "    test[col] = test[col].astype(np.float16)\n",
        "\n",
        "# Get feature list\n",
        "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]"
      ],
      "metadata": {
        "id": "3apqtSQzbZG1",
        "outputId": "aa12b938-6f58-4351-ff25-c2830cea0071",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1359/1359 [10:39<00:00,  2.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': \"binary_logloss\",\n",
        "    'boosting': 'dart',\n",
        "    'seed': CFG.seed,\n",
        "    'num_leaves': 100,\n",
        "    'learning_rate': 0.02,\n",
        "    'feature_fraction': 0.20,\n",
        "    'bagging_freq': 10,\n",
        "    'bagging_fraction': 0.50,\n",
        "    'n_jobs': -1,\n",
        "    'lambda_l2': 2,\n",
        "    'min_data_in_leaf': 40,\n",
        "    # 'device_type': 'gpu'\n",
        "    }"
      ],
      "metadata": {
        "id": "S00nxuAZbdBP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lgb_amex_metric(y_pred, y_true):\n",
        "    y_true = y_true.get_label()\n",
        "    return 'amex_metric', amex_metric(y_true, y_pred), True\n",
        "\n",
        "def train_and_evaluate(train):\n",
        "    # Create a numpy array to store out of folds predictions\n",
        "    oof_predictions = np.zeros(len(train))\n",
        "    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
        "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
        "        print(' ')\n",
        "        print('-'*50)\n",
        "        print(f'Training fold {fold} with {len(features)} features...')\n",
        "        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
        "        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
        "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
        "        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
        "        model = lgb.train(\n",
        "            params = params,\n",
        "            train_set = lgb_train,\n",
        "            num_boost_round = 10500,\n",
        "            valid_sets = [lgb_train, lgb_valid],\n",
        "            early_stopping_rounds = 100,\n",
        "            verbose_eval = 500,\n",
        "            feval = lgb_amex_metric\n",
        "            )\n",
        "        # Save best model\n",
        "        joblib.dump(model, f'lgbm_fold{fold}_seed{CFG.seed}.pkl')\n",
        "        # Predict validation\n",
        "        val_pred = model.predict(x_val)\n",
        "        # Add to out of folds array\n",
        "        oof_predictions[val_ind] = val_pred\n",
        "\n",
        "        # Compute fold metric\n",
        "        score = amex_metric(y_val, val_pred)\n",
        "        print(f'Our fold {fold} CV score is {score}')\n",
        "        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid, model\n",
        "        gc.collect()\n",
        "    # Compute out of folds metric\n",
        "    score = amex_metric(train[CFG.target], oof_predictions)\n",
        "    print(f'Our out of folds CV score is {score}')\n",
        "    # Create a dataframe to store out of folds predictions\n",
        "    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
        "    oof_df.to_csv(f'oof_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
        "\n",
        "train_and_evaluate(train)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-07-15T15:26:18.977741Z",
          "iopub.status.idle": "2022-07-15T15:26:18.978405Z",
          "shell.execute_reply.started": "2022-07-15T15:26:18.978196Z",
          "shell.execute_reply": "2022-07-15T15:26:18.978218Z"
        },
        "trusted": true,
        "id": "9p5Z6PX7uzlx",
        "outputId": "b29ace8a-7cb3-4a4f-b6ee-51f73210c545",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "--------------------------------------------------\n",
            "Training fold 0 with 1823 features...\n",
            "[500]\ttraining's binary_logloss: 0.257646\ttraining's amex_metric: 0.790797\tvalid_1's binary_logloss: 0.262181\tvalid_1's amex_metric: 0.779114\n",
            "[1000]\ttraining's binary_logloss: 0.210563\ttraining's amex_metric: 0.817391\tvalid_1's binary_logloss: 0.223419\tvalid_1's amex_metric: 0.793059\n",
            "[1500]\ttraining's binary_logloss: 0.196525\ttraining's amex_metric: 0.836847\tvalid_1's binary_logloss: 0.217905\tvalid_1's amex_metric: 0.797453\n",
            "[2000]\ttraining's binary_logloss: 0.183972\ttraining's amex_metric: 0.856783\tvalid_1's binary_logloss: 0.215043\tvalid_1's amex_metric: 0.800677\n",
            "[2500]\ttraining's binary_logloss: 0.175426\ttraining's amex_metric: 0.872316\tvalid_1's binary_logloss: 0.214201\tvalid_1's amex_metric: 0.801636\n",
            "[3000]\ttraining's binary_logloss: 0.166349\ttraining's amex_metric: 0.887321\tvalid_1's binary_logloss: 0.213295\tvalid_1's amex_metric: 0.802139\n",
            "[3500]\ttraining's binary_logloss: 0.157542\ttraining's amex_metric: 0.902073\tvalid_1's binary_logloss: 0.212732\tvalid_1's amex_metric: 0.802515\n",
            "[4000]\ttraining's binary_logloss: 0.14959\ttraining's amex_metric: 0.915943\tvalid_1's binary_logloss: 0.212621\tvalid_1's amex_metric: 0.802277\n",
            "[4500]\ttraining's binary_logloss: 0.141804\ttraining's amex_metric: 0.928763\tvalid_1's binary_logloss: 0.21254\tvalid_1's amex_metric: 0.801364\n",
            "[5000]\ttraining's binary_logloss: 0.134232\ttraining's amex_metric: 0.940493\tvalid_1's binary_logloss: 0.212527\tvalid_1's amex_metric: 0.801441\n",
            "[5500]\ttraining's binary_logloss: 0.127595\ttraining's amex_metric: 0.950557\tvalid_1's binary_logloss: 0.212541\tvalid_1's amex_metric: 0.801459\n",
            "[6000]\ttraining's binary_logloss: 0.121963\ttraining's amex_metric: 0.958793\tvalid_1's binary_logloss: 0.212548\tvalid_1's amex_metric: 0.802015\n",
            "[6500]\ttraining's binary_logloss: 0.116181\ttraining's amex_metric: 0.965711\tvalid_1's binary_logloss: 0.212622\tvalid_1's amex_metric: 0.801482\n",
            "[7000]\ttraining's binary_logloss: 0.109704\ttraining's amex_metric: 0.973394\tvalid_1's binary_logloss: 0.212761\tvalid_1's amex_metric: 0.801698\n",
            "[7500]\ttraining's binary_logloss: 0.103612\ttraining's amex_metric: 0.979965\tvalid_1's binary_logloss: 0.212907\tvalid_1's amex_metric: 0.800624\n",
            "[8000]\ttraining's binary_logloss: 0.0983604\ttraining's amex_metric: 0.984975\tvalid_1's binary_logloss: 0.213183\tvalid_1's amex_metric: 0.801552\n",
            "[8500]\ttraining's binary_logloss: 0.0939659\ttraining's amex_metric: 0.988702\tvalid_1's binary_logloss: 0.21339\tvalid_1's amex_metric: 0.801227\n",
            "[9000]\ttraining's binary_logloss: 0.0890789\ttraining's amex_metric: 0.991736\tvalid_1's binary_logloss: 0.213676\tvalid_1's amex_metric: 0.80088\n",
            "[9500]\ttraining's binary_logloss: 0.0848253\ttraining's amex_metric: 0.99433\tvalid_1's binary_logloss: 0.214023\tvalid_1's amex_metric: 0.80167\n",
            "[10000]\ttraining's binary_logloss: 0.0807378\ttraining's amex_metric: 0.996407\tvalid_1's binary_logloss: 0.214356\tvalid_1's amex_metric: 0.800663\n",
            "[10500]\ttraining's binary_logloss: 0.0772583\ttraining's amex_metric: 0.997661\tvalid_1's binary_logloss: 0.214734\tvalid_1's amex_metric: 0.800546\n",
            "Our fold 0 CV score is 0.8005460721345914\n",
            " \n",
            "--------------------------------------------------\n",
            "Training fold 1 with 1823 features...\n",
            "[500]\ttraining's binary_logloss: 0.257038\ttraining's amex_metric: 0.793168\tvalid_1's binary_logloss: 0.263752\tvalid_1's amex_metric: 0.771957\n",
            "[1000]\ttraining's binary_logloss: 0.209739\ttraining's amex_metric: 0.819053\tvalid_1's binary_logloss: 0.226073\tvalid_1's amex_metric: 0.784411\n",
            "[1500]\ttraining's binary_logloss: 0.195602\ttraining's amex_metric: 0.838744\tvalid_1's binary_logloss: 0.220926\tvalid_1's amex_metric: 0.788445\n",
            "[2000]\ttraining's binary_logloss: 0.183011\ttraining's amex_metric: 0.858599\tvalid_1's binary_logloss: 0.218329\tvalid_1's amex_metric: 0.790919\n",
            "[2500]\ttraining's binary_logloss: 0.174493\ttraining's amex_metric: 0.873934\tvalid_1's binary_logloss: 0.217561\tvalid_1's amex_metric: 0.793057\n",
            "[3000]\ttraining's binary_logloss: 0.165329\ttraining's amex_metric: 0.889128\tvalid_1's binary_logloss: 0.216991\tvalid_1's amex_metric: 0.792968\n",
            "[3500]\ttraining's binary_logloss: 0.156553\ttraining's amex_metric: 0.903246\tvalid_1's binary_logloss: 0.216621\tvalid_1's amex_metric: 0.792753\n",
            "[4000]\ttraining's binary_logloss: 0.148643\ttraining's amex_metric: 0.917305\tvalid_1's binary_logloss: 0.216383\tvalid_1's amex_metric: 0.792606\n",
            "[4500]\ttraining's binary_logloss: 0.140881\ttraining's amex_metric: 0.929322\tvalid_1's binary_logloss: 0.216093\tvalid_1's amex_metric: 0.792604\n",
            "[5000]\ttraining's binary_logloss: 0.133327\ttraining's amex_metric: 0.941078\tvalid_1's binary_logloss: 0.21598\tvalid_1's amex_metric: 0.792799\n",
            "[5500]\ttraining's binary_logloss: 0.126714\ttraining's amex_metric: 0.951159\tvalid_1's binary_logloss: 0.216044\tvalid_1's amex_metric: 0.792247\n",
            "[6000]\ttraining's binary_logloss: 0.121157\ttraining's amex_metric: 0.959427\tvalid_1's binary_logloss: 0.216169\tvalid_1's amex_metric: 0.792574\n",
            "[6500]\ttraining's binary_logloss: 0.115387\ttraining's amex_metric: 0.966191\tvalid_1's binary_logloss: 0.216261\tvalid_1's amex_metric: 0.793301\n",
            "[7000]\ttraining's binary_logloss: 0.108848\ttraining's amex_metric: 0.974136\tvalid_1's binary_logloss: 0.216431\tvalid_1's amex_metric: 0.793441\n",
            "[7500]\ttraining's binary_logloss: 0.102854\ttraining's amex_metric: 0.98071\tvalid_1's binary_logloss: 0.216642\tvalid_1's amex_metric: 0.793453\n",
            "[8000]\ttraining's binary_logloss: 0.0976199\ttraining's amex_metric: 0.985492\tvalid_1's binary_logloss: 0.21698\tvalid_1's amex_metric: 0.792964\n",
            "[8500]\ttraining's binary_logloss: 0.0932613\ttraining's amex_metric: 0.989131\tvalid_1's binary_logloss: 0.217161\tvalid_1's amex_metric: 0.793919\n",
            "[9000]\ttraining's binary_logloss: 0.0884089\ttraining's amex_metric: 0.992418\tvalid_1's binary_logloss: 0.217447\tvalid_1's amex_metric: 0.792865\n",
            "[9500]\ttraining's binary_logloss: 0.0841392\ttraining's amex_metric: 0.994688\tvalid_1's binary_logloss: 0.217821\tvalid_1's amex_metric: 0.793114\n",
            "[10000]\ttraining's binary_logloss: 0.0800841\ttraining's amex_metric: 0.996556\tvalid_1's binary_logloss: 0.218089\tvalid_1's amex_metric: 0.792504\n",
            "[10500]\ttraining's binary_logloss: 0.0766137\ttraining's amex_metric: 0.997754\tvalid_1's binary_logloss: 0.218389\tvalid_1's amex_metric: 0.793354\n",
            "Our fold 1 CV score is 0.7933542344121838\n",
            " \n",
            "--------------------------------------------------\n",
            "Training fold 2 with 1823 features...\n",
            "[500]\ttraining's binary_logloss: 0.256997\ttraining's amex_metric: 0.791033\tvalid_1's binary_logloss: 0.263968\tvalid_1's amex_metric: 0.774973\n",
            "[1000]\ttraining's binary_logloss: 0.209829\ttraining's amex_metric: 0.818814\tvalid_1's binary_logloss: 0.225841\tvalid_1's amex_metric: 0.788063\n",
            "[1500]\ttraining's binary_logloss: 0.195842\ttraining's amex_metric: 0.839366\tvalid_1's binary_logloss: 0.220268\tvalid_1's amex_metric: 0.793384\n",
            "[2000]\ttraining's binary_logloss: 0.183318\ttraining's amex_metric: 0.858361\tvalid_1's binary_logloss: 0.21754\tvalid_1's amex_metric: 0.795603\n",
            "[2500]\ttraining's binary_logloss: 0.174859\ttraining's amex_metric: 0.873661\tvalid_1's binary_logloss: 0.216606\tvalid_1's amex_metric: 0.797327\n",
            "[3000]\ttraining's binary_logloss: 0.165724\ttraining's amex_metric: 0.888535\tvalid_1's binary_logloss: 0.215895\tvalid_1's amex_metric: 0.79663\n",
            "[3500]\ttraining's binary_logloss: 0.156828\ttraining's amex_metric: 0.903262\tvalid_1's binary_logloss: 0.215458\tvalid_1's amex_metric: 0.79681\n",
            "[4000]\ttraining's binary_logloss: 0.148919\ttraining's amex_metric: 0.916727\tvalid_1's binary_logloss: 0.215292\tvalid_1's amex_metric: 0.796368\n",
            "[4500]\ttraining's binary_logloss: 0.141196\ttraining's amex_metric: 0.929291\tvalid_1's binary_logloss: 0.215134\tvalid_1's amex_metric: 0.796721\n",
            "[5000]\ttraining's binary_logloss: 0.13369\ttraining's amex_metric: 0.941194\tvalid_1's binary_logloss: 0.21508\tvalid_1's amex_metric: 0.795957\n",
            "[5500]\ttraining's binary_logloss: 0.12706\ttraining's amex_metric: 0.951056\tvalid_1's binary_logloss: 0.215137\tvalid_1's amex_metric: 0.79664\n",
            "[6000]\ttraining's binary_logloss: 0.121477\ttraining's amex_metric: 0.959213\tvalid_1's binary_logloss: 0.215211\tvalid_1's amex_metric: 0.796687\n",
            "[6500]\ttraining's binary_logloss: 0.115665\ttraining's amex_metric: 0.965947\tvalid_1's binary_logloss: 0.215233\tvalid_1's amex_metric: 0.79677\n",
            "[7000]\ttraining's binary_logloss: 0.109139\ttraining's amex_metric: 0.973554\tvalid_1's binary_logloss: 0.215396\tvalid_1's amex_metric: 0.796187\n",
            "[7500]\ttraining's binary_logloss: 0.103099\ttraining's amex_metric: 0.979769\tvalid_1's binary_logloss: 0.215505\tvalid_1's amex_metric: 0.796739\n",
            "[8000]\ttraining's binary_logloss: 0.0978535\ttraining's amex_metric: 0.984819\tvalid_1's binary_logloss: 0.215713\tvalid_1's amex_metric: 0.79708\n",
            "[8500]\ttraining's binary_logloss: 0.0934761\ttraining's amex_metric: 0.988868\tvalid_1's binary_logloss: 0.215881\tvalid_1's amex_metric: 0.796225\n",
            "[9000]\ttraining's binary_logloss: 0.0886625\ttraining's amex_metric: 0.992115\tvalid_1's binary_logloss: 0.216242\tvalid_1's amex_metric: 0.79641\n",
            "[9500]\ttraining's binary_logloss: 0.0844361\ttraining's amex_metric: 0.994416\tvalid_1's binary_logloss: 0.21644\tvalid_1's amex_metric: 0.796779\n",
            "[10000]\ttraining's binary_logloss: 0.0803626\ttraining's amex_metric: 0.996196\tvalid_1's binary_logloss: 0.216761\tvalid_1's amex_metric: 0.796642\n",
            "[10500]\ttraining's binary_logloss: 0.0768811\ttraining's amex_metric: 0.997387\tvalid_1's binary_logloss: 0.21714\tvalid_1's amex_metric: 0.796383\n",
            "Our fold 2 CV score is 0.7963833316544805\n",
            " \n",
            "--------------------------------------------------\n",
            "Training fold 3 with 1823 features...\n",
            "[500]\ttraining's binary_logloss: 0.256733\ttraining's amex_metric: 0.791922\tvalid_1's binary_logloss: 0.264807\tvalid_1's amex_metric: 0.770346\n",
            "[1000]\ttraining's binary_logloss: 0.209596\ttraining's amex_metric: 0.820099\tvalid_1's binary_logloss: 0.226953\tvalid_1's amex_metric: 0.782708\n",
            "[1500]\ttraining's binary_logloss: 0.195612\ttraining's amex_metric: 0.839843\tvalid_1's binary_logloss: 0.221376\tvalid_1's amex_metric: 0.788248\n",
            "[2000]\ttraining's binary_logloss: 0.183017\ttraining's amex_metric: 0.859867\tvalid_1's binary_logloss: 0.21861\tvalid_1's amex_metric: 0.791567\n",
            "[2500]\ttraining's binary_logloss: 0.174455\ttraining's amex_metric: 0.874141\tvalid_1's binary_logloss: 0.217713\tvalid_1's amex_metric: 0.790633\n",
            "[3000]\ttraining's binary_logloss: 0.165413\ttraining's amex_metric: 0.888875\tvalid_1's binary_logloss: 0.216947\tvalid_1's amex_metric: 0.791404\n",
            "[3500]\ttraining's binary_logloss: 0.156622\ttraining's amex_metric: 0.903714\tvalid_1's binary_logloss: 0.216404\tvalid_1's amex_metric: 0.791604\n",
            "[4000]\ttraining's binary_logloss: 0.148749\ttraining's amex_metric: 0.916833\tvalid_1's binary_logloss: 0.216064\tvalid_1's amex_metric: 0.791701\n",
            "[4500]\ttraining's binary_logloss: 0.141005\ttraining's amex_metric: 0.92892\tvalid_1's binary_logloss: 0.215951\tvalid_1's amex_metric: 0.792587\n",
            "[5000]\ttraining's binary_logloss: 0.133462\ttraining's amex_metric: 0.940719\tvalid_1's binary_logloss: 0.215916\tvalid_1's amex_metric: 0.791713\n",
            "[5500]\ttraining's binary_logloss: 0.126853\ttraining's amex_metric: 0.950597\tvalid_1's binary_logloss: 0.215935\tvalid_1's amex_metric: 0.792344\n",
            "[6000]\ttraining's binary_logloss: 0.121255\ttraining's amex_metric: 0.959146\tvalid_1's binary_logloss: 0.21603\tvalid_1's amex_metric: 0.792423\n",
            "[6500]\ttraining's binary_logloss: 0.115419\ttraining's amex_metric: 0.966391\tvalid_1's binary_logloss: 0.216081\tvalid_1's amex_metric: 0.793038\n",
            "[7000]\ttraining's binary_logloss: 0.108982\ttraining's amex_metric: 0.973772\tvalid_1's binary_logloss: 0.216249\tvalid_1's amex_metric: 0.792151\n",
            "[7500]\ttraining's binary_logloss: 0.102931\ttraining's amex_metric: 0.980318\tvalid_1's binary_logloss: 0.216449\tvalid_1's amex_metric: 0.792443\n",
            "[8000]\ttraining's binary_logloss: 0.0976997\ttraining's amex_metric: 0.985123\tvalid_1's binary_logloss: 0.21677\tvalid_1's amex_metric: 0.79153\n",
            "[8500]\ttraining's binary_logloss: 0.0933147\ttraining's amex_metric: 0.988779\tvalid_1's binary_logloss: 0.216942\tvalid_1's amex_metric: 0.79208\n",
            "[9000]\ttraining's binary_logloss: 0.088494\ttraining's amex_metric: 0.992012\tvalid_1's binary_logloss: 0.217277\tvalid_1's amex_metric: 0.792603\n",
            "[9500]\ttraining's binary_logloss: 0.0842697\ttraining's amex_metric: 0.99463\tvalid_1's binary_logloss: 0.217533\tvalid_1's amex_metric: 0.792807\n",
            "[10000]\ttraining's binary_logloss: 0.080216\ttraining's amex_metric: 0.996495\tvalid_1's binary_logloss: 0.21783\tvalid_1's amex_metric: 0.792073\n",
            "[10500]\ttraining's binary_logloss: 0.0767261\ttraining's amex_metric: 0.997692\tvalid_1's binary_logloss: 0.218171\tvalid_1's amex_metric: 0.792139\n",
            "Our fold 3 CV score is 0.7921389500453673\n",
            " \n",
            "--------------------------------------------------\n",
            "Training fold 4 with 1823 features...\n",
            "[500]\ttraining's binary_logloss: 0.257409\ttraining's amex_metric: 0.790761\tvalid_1's binary_logloss: 0.263242\tvalid_1's amex_metric: 0.77453\n",
            "[1000]\ttraining's binary_logloss: 0.210306\ttraining's amex_metric: 0.818144\tvalid_1's binary_logloss: 0.224777\tvalid_1's amex_metric: 0.78673\n",
            "[1500]\ttraining's binary_logloss: 0.196198\ttraining's amex_metric: 0.838941\tvalid_1's binary_logloss: 0.219132\tvalid_1's amex_metric: 0.791785\n",
            "[2000]\ttraining's binary_logloss: 0.183609\ttraining's amex_metric: 0.858366\tvalid_1's binary_logloss: 0.216347\tvalid_1's amex_metric: 0.795518\n",
            "[2500]\ttraining's binary_logloss: 0.175081\ttraining's amex_metric: 0.873597\tvalid_1's binary_logloss: 0.215549\tvalid_1's amex_metric: 0.796821\n",
            "[3000]\ttraining's binary_logloss: 0.165939\ttraining's amex_metric: 0.888091\tvalid_1's binary_logloss: 0.214633\tvalid_1's amex_metric: 0.796666\n",
            "[3500]\ttraining's binary_logloss: 0.157129\ttraining's amex_metric: 0.902922\tvalid_1's binary_logloss: 0.214189\tvalid_1's amex_metric: 0.79619\n",
            "[4000]\ttraining's binary_logloss: 0.149246\ttraining's amex_metric: 0.916099\tvalid_1's binary_logloss: 0.213872\tvalid_1's amex_metric: 0.796276\n",
            "[4500]\ttraining's binary_logloss: 0.141547\ttraining's amex_metric: 0.928628\tvalid_1's binary_logloss: 0.213735\tvalid_1's amex_metric: 0.796018\n",
            "[5000]\ttraining's binary_logloss: 0.133996\ttraining's amex_metric: 0.9399\tvalid_1's binary_logloss: 0.213729\tvalid_1's amex_metric: 0.797013\n",
            "[5500]\ttraining's binary_logloss: 0.127324\ttraining's amex_metric: 0.949969\tvalid_1's binary_logloss: 0.213668\tvalid_1's amex_metric: 0.796618\n",
            "[6000]\ttraining's binary_logloss: 0.121749\ttraining's amex_metric: 0.958579\tvalid_1's binary_logloss: 0.213529\tvalid_1's amex_metric: 0.797278\n",
            "[6500]\ttraining's binary_logloss: 0.11589\ttraining's amex_metric: 0.965505\tvalid_1's binary_logloss: 0.213723\tvalid_1's amex_metric: 0.797141\n",
            "[7000]\ttraining's binary_logloss: 0.109415\ttraining's amex_metric: 0.973517\tvalid_1's binary_logloss: 0.213749\tvalid_1's amex_metric: 0.796851\n",
            "[7500]\ttraining's binary_logloss: 0.103431\ttraining's amex_metric: 0.979817\tvalid_1's binary_logloss: 0.213952\tvalid_1's amex_metric: 0.79678\n",
            "[8000]\ttraining's binary_logloss: 0.0981562\ttraining's amex_metric: 0.984812\tvalid_1's binary_logloss: 0.214069\tvalid_1's amex_metric: 0.796888\n",
            "[8500]\ttraining's binary_logloss: 0.0937683\ttraining's amex_metric: 0.988586\tvalid_1's binary_logloss: 0.214235\tvalid_1's amex_metric: 0.796492\n",
            "[9000]\ttraining's binary_logloss: 0.0889363\ttraining's amex_metric: 0.99202\tvalid_1's binary_logloss: 0.214527\tvalid_1's amex_metric: 0.796404\n",
            "[9500]\ttraining's binary_logloss: 0.0846264\ttraining's amex_metric: 0.99432\tvalid_1's binary_logloss: 0.214796\tvalid_1's amex_metric: 0.796668\n",
            "[10000]\ttraining's binary_logloss: 0.0805648\ttraining's amex_metric: 0.996303\tvalid_1's binary_logloss: 0.214885\tvalid_1's amex_metric: 0.796342\n",
            "[10500]\ttraining's binary_logloss: 0.0770983\ttraining's amex_metric: 0.997563\tvalid_1's binary_logloss: 0.215105\tvalid_1's amex_metric: 0.79727\n",
            "Our fold 4 CV score is 0.7972702493404904\n",
            "Our out of folds CV score is 0.7960623529408077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del train\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "id": "P2llPNqqOKTT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.018388,
          "end_time": "2022-07-15T16:48:45.862462",
          "exception": false,
          "start_time": "2022-07-15T16:48:45.844074",
          "status": "completed"
        },
        "tags": [],
        "id": "bf46dad6"
      },
      "source": [
        "# Test part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T16:48:45.901178Z",
          "iopub.status.busy": "2022-07-15T16:48:45.900848Z",
          "iopub.status.idle": "2022-07-15T16:48:45.907526Z",
          "shell.execute_reply": "2022-07-15T16:48:45.906709Z"
        },
        "papermill": {
          "duration": 0.027751,
          "end_time": "2022-07-15T16:48:45.909278",
          "exception": false,
          "start_time": "2022-07-15T16:48:45.881527",
          "status": "completed"
        },
        "tags": [],
        "id": "c28f1826"
      },
      "outputs": [],
      "source": [
        "# CALCULATE SIZE OF EACH SEPARATE TEST PART\n",
        "def get_rows(customers, test, NUM_PARTS = 4, verbose = ''):\n",
        "    chunk = len(customers)//NUM_PARTS\n",
        "    if verbose != '':\n",
        "        print(f'We will process {verbose} data as {NUM_PARTS} separate parts.')\n",
        "        print(f'There will be {chunk} customers in each part (except the last part).')\n",
        "        print('Below are number of rows in each part:')\n",
        "    rows = []\n",
        "\n",
        "    for k in range(NUM_PARTS):\n",
        "        if k==NUM_PARTS-1: cc = customers[k*chunk:]\n",
        "        else: cc = customers[k*chunk:(k+1)*chunk]\n",
        "        s = test.loc[test.customer_ID.isin(cc)].shape[0]\n",
        "        rows.append(s)\n",
        "    if verbose != '': print( rows )\n",
        "    return rows,chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T16:48:45.947705Z",
          "iopub.status.busy": "2022-07-15T16:48:45.947377Z",
          "iopub.status.idle": "2022-07-15T16:48:47.039525Z",
          "shell.execute_reply": "2022-07-15T16:48:47.038640Z"
        },
        "papermill": {
          "duration": 1.113806,
          "end_time": "2022-07-15T16:48:47.041416",
          "exception": false,
          "start_time": "2022-07-15T16:48:45.927610",
          "status": "completed"
        },
        "tags": [],
        "id": "8c7e70c5",
        "outputId": "37319487-9123-4f69-a97c-8c4380090e33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We will process test data as 4 separate parts.\n",
            "There will be 231155 customers in each part (except the last part).\n",
            "Below are number of rows in each part:\n",
            "[231155, 231155, 231155, 231156]\n"
          ]
        }
      ],
      "source": [
        "# COMPUTE SIZE OF 4 PARTS FOR TEST DATA\n",
        "NUM_PARTS = 4\n",
        "\n",
        "customers = test[['customer_ID']].drop_duplicates().sort_index().values.flatten()\n",
        "rows,num_cust = get_rows(customers, test[['customer_ID']], NUM_PARTS = NUM_PARTS, verbose = 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T16:48:47.081924Z",
          "iopub.status.busy": "2022-07-15T16:48:47.081615Z",
          "iopub.status.idle": "2022-07-15T16:50:55.407348Z",
          "shell.execute_reply": "2022-07-15T16:50:55.406352Z"
        },
        "papermill": {
          "duration": 128.349422,
          "end_time": "2022-07-15T16:50:55.410249",
          "exception": false,
          "start_time": "2022-07-15T16:48:47.060827",
          "status": "completed"
        },
        "tags": [],
        "id": "9cf53fd3",
        "outputId": "2ebcdee2-1d31-42cd-e0cb-d03dd91ac4eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reading test data...\n",
            "=> Test part 1 has shape (231155, 1823)\n",
            "\n",
            "Reading test data...\n",
            "=> Test part 2 has shape (231155, 1823)\n",
            "\n",
            "Reading test data...\n",
            "=> Test part 3 has shape (231155, 1823)\n",
            "\n",
            "Reading test data...\n",
            "=> Test part 4 has shape (231156, 1823)\n"
          ]
        }
      ],
      "source": [
        "# INFER TEST DATA IN PARTS\n",
        "skip_rows = 0\n",
        "skip_cust = 0\n",
        "test_preds = []\n",
        "\n",
        "for k in range(NUM_PARTS):\n",
        "    \n",
        "    # READ PART OF TEST DATA\n",
        "    print(f'\\nReading test data...')\n",
        "    test_copy = test.iloc[skip_rows:skip_rows+rows[k]].copy()\n",
        "    test_copy = test_copy.set_index('customer_ID')\n",
        "    skip_rows += rows[k]\n",
        "    print(f'=> Test part {k+1} has shape', test_copy.shape )\n",
        "    \n",
        "    # PROCESS AND FEATURE ENGINEER PART OF TEST DATA\n",
        "    if k==NUM_PARTS-1: test_copy = test_copy.loc[customers[skip_cust:]]\n",
        "    else: test_copy = test_copy.loc[customers[skip_cust:skip_cust+num_cust]]\n",
        "    skip_cust += num_cust\n",
        "        \n",
        "    # INFER XGB MODELS ON TEST DATA\n",
        "    model = joblib.load(f'lgbm_fold0_seed{CFG.seed}.pkl')\n",
        "    preds = model.predict(test_copy)\n",
        "    for f in range(1,CFG.n_folds):\n",
        "        model = joblib.load(f'lgbm_fold{f}_seed{CFG.seed}.pkl')\n",
        "        preds += model.predict(test_copy)\n",
        "    preds /= CFG.n_folds\n",
        "    test_preds.append(preds)\n",
        "\n",
        "    # CLEAN MEMORY\n",
        "    del test_copy, model\n",
        "    _ = gc.collect()\n",
        "\n",
        "del test\n",
        "_ = gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.067515,
          "end_time": "2022-07-15T16:50:55.538577",
          "exception": false,
          "start_time": "2022-07-15T16:50:55.471062",
          "status": "completed"
        },
        "tags": [],
        "id": "02259545"
      },
      "source": [
        "# Submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T16:50:55.628196Z",
          "iopub.status.busy": "2022-07-15T16:50:55.627855Z",
          "iopub.status.idle": "2022-07-15T16:51:02.864876Z",
          "shell.execute_reply": "2022-07-15T16:51:02.864114Z"
        },
        "papermill": {
          "duration": 7.268354,
          "end_time": "2022-07-15T16:51:02.866646",
          "exception": false,
          "start_time": "2022-07-15T16:50:55.598292",
          "status": "completed"
        },
        "tags": [],
        "id": "00d908fd",
        "outputId": "70d2f69e-a382-4dc3-eaf3-f691e6cd8ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file shape is (924621, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         customer_ID  prediction\n",
              "0  00000469ba478561f23a92a868bd366de6f6527a684c9a...    0.017983\n",
              "1  00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...    0.000407\n",
              "2  0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...    0.022674\n",
              "3  00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...    0.183241\n",
              "4  00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...    0.907943"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d070374-d03c-4398-a1d4-eb7abb111dec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_ID</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
              "      <td>0.017983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...</td>\n",
              "      <td>0.000407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...</td>\n",
              "      <td>0.022674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...</td>\n",
              "      <td>0.183241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...</td>\n",
              "      <td>0.907943</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d070374-d03c-4398-a1d4-eb7abb111dec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d070374-d03c-4398-a1d4-eb7abb111dec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d070374-d03c-4398-a1d4-eb7abb111dec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# WRITE SUBMISSION FILE\n",
        "test = pd.DataFrame(index=customers,data={'prediction': np.concatenate(test_preds)})\n",
        "sub = pd.read_csv('sample_submission.csv')[['customer_ID']]\n",
        "sub['customer_ID_hash'] = sub['customer_ID'].copy()\n",
        "sub = sub.set_index('customer_ID_hash')\n",
        "sub = sub.merge(test[['prediction']], left_index=True, right_index=True, how='left')\n",
        "sub = sub.reset_index(drop=True)\n",
        "\n",
        "# DISPLAY PREDICTIONS\n",
        "sub.to_csv(f'submission_lgb_v14_seed{CFG.seed}_fold{CFG.n_folds}.csv',index=False)\n",
        "print('Submission file shape is', sub.shape )\n",
        "sub.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T16:51:02.918871Z",
          "iopub.status.busy": "2022-07-15T16:51:02.918494Z",
          "iopub.status.idle": "2022-07-15T16:51:03.267833Z",
          "shell.execute_reply": "2022-07-15T16:51:03.266949Z"
        },
        "papermill": {
          "duration": 0.374502,
          "end_time": "2022-07-15T16:51:03.269960",
          "exception": false,
          "start_time": "2022-07-15T16:51:02.895458",
          "status": "completed"
        },
        "tags": [],
        "id": "533e5941",
        "outputId": "6a091352-5e62-40f4-eff6-3fb15a701909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbsklEQVR4nO3df5RfdX3n8efLxABdhQQyRkxSQzVtN9BjxCzEtbtFUAjRGnqKnLBWIic1WkOPXd2WoN1F0fTA7lGULeJGkxL8FbK0yqyNpmmAZbtrIIPEQEJZRghmYiRjEhJdBEl47x/3PXoZv5+Zb+bHdzIzr8c53zP3vu/n3s/n5sf3NffH93sVEZiZmTXykpEegJmZHb8cEmZmVuSQMDOzIoeEmZkVOSTMzKzIIWFmZkUOCbMRJmmXpLfk9EckfXGA29kh6bwhHZyNew4JG3Uk/bT2ekHSz2rz7xrA9u6R9Md9LJ8lKWp97JK0YnB70VhE/FVEFMdSG9Otkj7Za90zI+Ke4RiXjV8TR3oAZscqIl7WMy1pF/DHEfGPLeh6ckQckfRGYLOkbRHx7XoDSRMj4kgLxmLWEj6SsDFD0kskrZD0fUn7Ja2XdGouO1HSl7P+tKStkqZJWgn8G+Cv8yjhr/vrJyK+A+wAzpJ0nqQuSVdL+hHwN32NI8fybklP5rKP9tqHj0n6cm3+dyX9nxzzbknvkbQMeBfwFznm/5Ft66etTpD0GUk/zNdnJJ2Qy3rG/GFJ+yTtlXRlrc+FknZK+omkPZL+w4D/UmzUc0jYWPKnwCXA7wGvAg4CN+eyJcApwEzgNOD9wM8i4qPA/wKuioiXRcRVfXWgypuAM4EHs/xK4FTg1cCyvsYhaQ5wC/DuXHYaMKPQ16uBbwH/FWgD5gLbImIV8BXgP+eYf7/B6h8F5uc6rwPOAf6ytvyV+ecxHVgK3CxpSi5bDbwvIl4OnAXc1defiY1tDgkbS94PfDQiuiLiOeBjwKWSJgLPU70hvzYijkbEAxFx+Bi3/2PgAPBFYEVEbM76C8C1EfFcRPysn3FcCnwzIu7NZf8x12/k3wH/GBFfi4jnI2J/RGxrcqzvAq6LiH0R0Q18nCqYejyfy5+PiA3AT4Hfqi2bI+nkiDgYEd9tsk8bg3xNwsaSVwNfl1R/0z0KTAO+RHUUsU7SZODLVG/kzx/D9qcWrjd0R8SzTY7jVcDunmJE/D9J+wv9zQS+fwzjq3sV8GRt/sms9djfa1+eAXqu9fwh1VHH9ZK2UwXidwY4DhvlfCRhY8lu4OKImFx7nRgRe/I35o9HxBzgXwNvB67I9Qb7Vci91y+OA9hL9eYPgKRfozrCKe3Pa5rss7cfUoVVj1/PWr8iYmtELAJeAXwDWN/MejY2OSRsLPk8sDLP5SOpTdKinH6zpN+RNAE4THVKpec3/aeA32jFOIA7gLfnBelJwHWU/x9+BXiLpMskTZR0mqS5TY75a8BfZt9Tgf9EdfTUJ0mTJL1L0il5lHWY8ukwGwccEjaWfBZoB/5B0k+ALcC5ueyVVG/Qh4FHgP9JdQqqZ71LJR2UdNNwjiMidgDLga9SHVUcBLoabSQifgAsBD5MdS1kG9VFaKguLs/Ju56+0WD1TwIdwHbgIeC7WWvGu4Fdkg5TXV855s+e2NghP3TIzMxKfCRhZmZFDgkzMytySJiZWZFDwszMisbch+mmTp0as2bNGulhmJmNKg888MCPI6Ktd33MhcSsWbPo6OgY6WGYmY0qkp5sVPfpJjMzK3JImJlZkUPCzMyKHBJmZlbkkDAzsyKHhJmZFTkkzMysyCFhZmZFDgkzMysac5+4HoxZK/7+F9O7rn/bCI7EzOz44CMJMzMrckiYmVmRQ8LMzIocEmZmVuSQMDOzIoeEmZkVNR0SkiZIelDSN3P+DEn3SeqUdLukSVk/Iec7c/ms2jauyfqjki6q1RdkrVPSilq9YR9mZtYax3Ik8UHgkdr8DcCNEfFa4CCwNOtLgYNZvzHbIWkOsBg4E1gAfC6DZwJwM3AxMAe4PNv21YeZmbVAUyEhaQbwNuCLOS/gfOCObLIWuCSnF+U8ufyCbL8IWBcRz0XEE0AncE6+OiPi8Yj4ObAOWNRPH2Zm1gLNHkl8BvgL4IWcPw14OiKO5HwXMD2npwO7AXL5oWz/i3qvdUr1vvp4EUnLJHVI6uju7m5yl8zMrD/9hoSktwP7IuKBFoxnQCJiVUTMi4h5bW1tIz0cM7Mxo5nvbnoT8A5JC4ETgZOBzwKTJU3M3/RnAHuy/R5gJtAlaSJwCrC/Vu9RX6dRfX8ffZiZWQv0eyQREddExIyImEV14fmuiHgXcDdwaTZbAtyZ0+05Ty6/KyIi64vz7qczgNnA/cBWYHbeyTQp+2jPdUp9mJlZCwzmcxJXAx+S1El1/WB11lcDp2X9Q8AKgIjYAawHdgLfBpZHxNE8SrgK2Eh199T6bNtXH2Zm1gLH9FXhEXEPcE9OP051Z1LvNs8C7yysvxJY2aC+AdjQoN6wDzMzaw1/4trMzIocEmZmVuSQMDOzIoeEmZkVOSTMzKzIIWFmZkUOCTMzK3JImJlZkUPCzMyKHBJmZlbkkDAzsyKHhJmZFTkkzMysyCFhZmZFDgkzMytq5hnXJ0q6X9L3JO2Q9PGs3yrpCUnb8jU365J0k6ROSdslnV3b1hJJj+VrSa3+BkkP5To3SVLWT5W0KdtvkjRl6P8IzMyspJkjieeA8yPidcBcYIGk+bnszyNibr62Ze1iqkeTzgaWAbdA9YYPXAucS/UgoWtrb/q3AO+trbcg6yuAzRExG9ic82Zm1iLNPOM6IuKnOfvSfEUfqywCbsv1tgCTJZ0OXARsiogDEXEQ2EQVOKcDJ0fElnyu9W3AJbVtrc3ptbW6mZm1QFPXJCRNkLQN2Ef1Rn9fLlqZp5RulHRC1qYDu2urd2Wtr3pXgzrAtIjYm9M/AqYVxrdMUoekju7u7mZ2yczMmtBUSETE0YiYC8wAzpF0FnAN8NvAvwJOBa4etlFWYwgKRzARsSoi5kXEvLa2tuEchpnZuHJMdzdFxNPA3cCCiNibp5SeA/6G6joDwB5gZm21GVnrqz6jQR3gqTwdRf7cdyzjNTOzwWnm7qY2SZNz+iTgrcA/1968RXWt4OFcpR24Iu9ymg8cylNGG4ELJU3JC9YXAhtz2WFJ83NbVwB31rbVcxfUklrdzMxaYGITbU4H1kqaQBUq6yPim5LuktQGCNgGvD/bbwAWAp3AM8CVABFxQNIngK3Z7rqIOJDTHwBuBU4CvpUvgOuB9ZKWAk8Clw10R83M7Nj1GxIRsR14fYP6+YX2ASwvLFsDrGlQ7wDOalDfD1zQ3xjNzGx4+BPXZmZW5JAwM7Mih4SZmRU5JMzMrMghYWZmRQ4JMzMrckiYmVmRQ8LMzIocEmZmVuSQMDOzIoeEmZkVOSTMzKzIIWFmZkUOCTMzK3JImJlZkUPCzMyKmnl86YmS7pf0PUk7JH0862dIuk9Sp6TbJU3K+gk535nLZ9W2dU3WH5V0Ua2+IGudklbU6g37MDOz1mjmSOI54PyIeB0wF1iQz66+AbgxIl4LHASWZvulwMGs35jtkDQHWAycCSwAPidpQj4W9WbgYmAOcHm2pY8+zMysBfoNiaj8NGdfmq8AzgfuyPpa4JKcXpTz5PILJCnr6yLiuYh4guoZ2OfkqzMiHo+InwPrgEW5TqkPMzNrgaauSeRv/NuAfcAm4PvA0xFxJJt0AdNzejqwGyCXHwJOq9d7rVOqn9ZHH73Ht0xSh6SO7u7uZnbJzMya0FRIRMTRiJgLzKD6zf+3h3VUxygiVkXEvIiY19bWNtLDMTMbM47p7qaIeBq4G3gjMFnSxFw0A9iT03uAmQC5/BRgf73ea51SfX8ffZiZWQs0c3dTm6TJOX0S8FbgEaqwuDSbLQHuzOn2nCeX3xURkfXFeffTGcBs4H5gKzA772SaRHVxuz3XKfVhZmYtMLH/JpwOrM27kF4CrI+Ib0raCayT9EngQWB1tl8NfElSJ3CA6k2fiNghaT2wEzgCLI+IowCSrgI2AhOANRGxI7d1daEPMzNrgX5DIiK2A69vUH+c6vpE7/qzwDsL21oJrGxQ3wBsaLYPMzNrDX/i2szMihwSZmZW5JAwM7Mih4SZmRU5JMzMrMghYWZmRQ4JMzMrckiYmVmRQ8LMzIocEmZmVuSQMDOzIoeEmZkVOSTMzKzIIWFmZkUOCTMzK3JImJlZUTOPL50p6W5JOyXtkPTBrH9M0h5J2/K1sLbONZI6JT0q6aJafUHWOiWtqNXPkHRf1m/Px5iSjzq9Pev3SZo1lDtvZmZ9a+ZI4gjw4YiYA8wHlkuak8tujIi5+doAkMsWA2cCC4DPSZqQjz+9GbgYmANcXtvODbmt1wIHgaVZXwoczPqN2c7MzFqk35CIiL0R8d2c/gnwCDC9j1UWAesi4rmIeALopHoE6TlAZ0Q8HhE/B9YBiyQJOB+4I9dfC1xS29banL4DuCDbm5lZCxzTNYk83fN64L4sXSVpu6Q1kqZkbTqwu7ZaV9ZK9dOApyPiSK/6i7aVyw9l+97jWiapQ1JHd3f3seySmZn1oemQkPQy4G+BP4uIw8AtwGuAucBe4FPDMsImRMSqiJgXEfPa2tpGahhmZmNOUyEh6aVUAfGViPg7gIh4KiKORsQLwBeoTicB7AFm1lafkbVSfT8wWdLEXvUXbSuXn5LtzcysBZq5u0nAauCRiPh0rX56rdkfAA/ndDuwOO9MOgOYDdwPbAVm551Mk6gubrdHRAB3A5fm+kuAO2vbWpLTlwJ3ZXszM2uBif034U3Au4GHJG3L2keo7k6aCwSwC3gfQETskLQe2El1Z9TyiDgKIOkqYCMwAVgTETtye1cD6yR9EniQKpTIn1+S1AkcoAoWMzNrkX5DIiL+CWh0R9GGPtZZCaxsUN/QaL2IeJxfnq6q158F3tnfGM3MbHj4E9dmZlbkkDAzsyKHhJmZFTkkzMysyCFhZmZFDgkzMytySJiZWZFDwszMihwSZmZW5JAwM7Mih4SZmRU5JMzMrMghYWZmRQ4JMzMrckiYmVlRM0+mmynpbkk7Je2Q9MGsnyppk6TH8ueUrEvSTZI6JW2XdHZtW0uy/WOSltTqb5D0UK5zUz4Nr9iHmZm1RjNHEkeAD0fEHGA+sFzSHGAFsDkiZgObcx7gYqpHls4GlgG3QPWGD1wLnEv1gKFra2/6twDvra23IOulPszMrAX6DYmI2BsR383pnwCPANOBRcDabLYWuCSnFwG3RWULMDmfh30RsCkiDkTEQWATsCCXnRwRW/L51bf12lajPszMrAWO6ZqEpFnA64H7gGkRsTcX/QiYltPTgd211bqy1le9q0GdPvroPa5lkjokdXR3dx/LLpmZWR+aDglJLwP+FviziDhcX5ZHADHEY3uRvvqIiFURMS8i5rW1tQ3nMMzMxpWmQkLSS6kC4isR8XdZfipPFZE/92V9DzCztvqMrPVVn9Gg3lcfZmbWAs3c3SRgNfBIRHy6tqgd6LlDaQlwZ61+Rd7lNB84lKeMNgIXSpqSF6wvBDbmssOS5mdfV/TaVqM+zMysBSY20eZNwLuBhyRty9pHgOuB9ZKWAk8Cl+WyDcBCoBN4BrgSICIOSPoEsDXbXRcRB3L6A8CtwEnAt/JFH32YmVkL9BsSEfFPgAqLL2jQPoDlhW2tAdY0qHcAZzWo72/Uh5mZtYY/cW1mZkUOCTMzK3JImJlZkUPCzMyKHBJmZlbkkDAzsyKHhJmZFTkkzMysyCFhZmZFDgkzMytySJiZWZFDwszMihwSZmZW5JAwM7Mih4SZmRU5JMzMrKiZx5eukbRP0sO12sck7ZG0LV8La8uukdQp6VFJF9XqC7LWKWlFrX6GpPuyfrukSVk/Iec7c/msodppMzNrTjNHErcCCxrUb4yIufnaACBpDrAYODPX+ZykCZImADcDFwNzgMuzLcANua3XAgeBpVlfChzM+o3ZzszMWqjfkIiIe4ED/bVLi4B1EfFcRDxB9Zzrc/LVGRGPR8TPgXXAIkkCzgfuyPXXApfUtrU2p+8ALsj2ZmbWIoO5JnGVpO15OmpK1qYDu2tturJWqp8GPB0RR3rVX7StXH4o2/8KScskdUjq6O7uHsQumZlZ3UBD4hbgNcBcYC/wqSEb0QBExKqImBcR89ra2kZyKGZmY8qAQiIinoqIoxHxAvAFqtNJAHuAmbWmM7JWqu8HJkua2Kv+om3l8lOyvZmZtciAQkLS6bXZPwB67nxqBxbnnUlnALOB+4GtwOy8k2kS1cXt9ogI4G7g0lx/CXBnbVtLcvpS4K5sb2ZmLTKxvwaSvgacB0yV1AVcC5wnaS4QwC7gfQARsUPSemAncARYHhFHcztXARuBCcCaiNiRXVwNrJP0SeBBYHXWVwNfktRJdeF88aD31szMjkm/IRERlzcor25Q62m/EljZoL4B2NCg/ji/PF1Vrz8LvLO/8ZmZ2fDxJ67NzKzIIWFmZkUOCTMzK3JImJlZkUPCzMyKHBJmZlbkkDAzsyKHhJmZFTkkzMysyCFhZmZFDgkzMytySJiZWZFDwszMihwSZmZW5JAwM7OifkNC0hpJ+yQ9XKudKmmTpMfy55SsS9JNkjolbZd0dm2dJdn+MUlLavU3SHoo17lJkvrqw8zMWqeZI4lbgQW9aiuAzRExG9ic8wAXUz2ydDawDLgFqjd8qifanUv1gKFra2/6twDvra23oJ8+zMysRfoNiYi4l+rxoXWLgLU5vRa4pFa/LSpbgMn5POyLgE0RcSAiDgKbgAW57OSI2JLPr76t17Ya9WFmZi0y0GsS0yJib07/CJiW09OB3bV2XVnrq97VoN5XH2Zm1iKDvnCdRwAxBGMZcB+SlknqkNTR3d09nEMxMxtXBhoST+WpIvLnvqzvAWbW2s3IWl/1GQ3qffXxKyJiVUTMi4h5bW1tA9wlMzPrbaAh0Q703KG0BLizVr8i73KaDxzKU0YbgQslTckL1hcCG3PZYUnz866mK3ptq1EfZmbWIhP7ayDpa8B5wFRJXVR3KV0PrJe0FHgSuCybbwAWAp3AM8CVABFxQNIngK3Z7rqI6LkY/gGqO6hOAr6VL/row8zMWqTfkIiIywuLLmjQNoDlhe2sAdY0qHcAZzWo72/Uh5mZtY4/cW1mZkUOCTMzK3JImJlZkUPCzMyKHBJmZlbkkDAzsyKHhJmZFTkkzMysyCFhZmZFDgkzMytySJiZWZFDwszMihwSZmZW5JAwM7Mih4SZmRU5JMzMrGhQISFpl6SHJG2T1JG1UyVtkvRY/pySdUm6SVKnpO2Szq5tZ0m2f0zSklr9Dbn9zlxXgxmvmZkdm6E4knhzRMyNiHk5vwLYHBGzgc05D3AxMDtfy4BboAoVqkeingucA1zbEyzZ5r219RYMwXjNzKxJ/T6+dAAWUT0TG2AtcA9wddZvy0ecbpE0WdLp2XZTzzOvJW0CFki6Bzg5IrZk/TbgEn75DOxhNWvF3/9ietf1b2tFl2Zmx53BHkkE8A+SHpC0LGvTImJvTv8ImJbT04HdtXW7stZXvatB/VdIWiapQ1JHd3f3YPbHzMxqBnsk8bsRsUfSK4BNkv65vjAiQlIMso9+RcQqYBXAvHnzhr0/M7PxYlBHEhGxJ3/uA75OdU3hqTyNRP7cl833ADNrq8/IWl/1GQ3qZmbWIgMOCUn/QtLLe6aBC4GHgXag5w6lJcCdOd0OXJF3Oc0HDuVpqY3AhZKm5AXrC4GNueywpPl5V9MVtW2ZmVkLDOZ00zTg63lX6kTgqxHxbUlbgfWSlgJPApdl+w3AQqATeAa4EiAiDkj6BLA1213XcxEb+ABwK3AS1QXrlly0NjOzyoBDIiIeB17XoL4fuKBBPYDlhW2tAdY0qHcAZw10jGZmNjj+xLWZmRUNx+ckzMysBeqf54Lh+UyXjyTMzKzIIWFmZkUOCTMzK/I1iSb4e5zMbLzykYSZmRU5JMzMrMghYWZmRQ4JMzMr8oXrY+SL2GY2nvhIwszMinwkMQg+qjCzVuv9VRzDzSExRBwYZjYWOSSGgQPDzIZSq48e6hwSw6yvv1wHiJnVjWQYlBz3ISFpAfBZYALwxYi4foSHNGQG8w/CAWN2/Dge39yHynEdEpImADcDbwW6gK2S2iNi58iObOSN5X+UDsDjy1j+t2b9O65DAjgH6MxHpSJpHbAIGPchMZb5Tcns+HG8h8R0YHdtvgs4t3cjScuAZTn7U0mPDrC/qcCPB7juaOV9Hh+8z+OAbhjUPr+6UfF4D4mmRMQqYNVgtyOpIyLmDcGQRg3v8/jgfR4fhmOfj/dPXO8BZtbmZ2TNzMxa4HgPia3AbElnSJoELAbaR3hMZmbjxnF9uikijki6CthIdQvsmojYMYxdDvqU1SjkfR4fvM/jw5DvsyJiqLdpZmZjxPF+usnMzEaQQ8LMzIrGZUhIWiDpUUmdklY0WH6CpNtz+X2SZrV+lEOriX3+kKSdkrZL2iyp4T3To0l/+1xr94eSQtKovl2ymf2VdFn+Pe+Q9NVWj3GoNfHv+tcl3S3pwfy3vXAkxjmUJK2RtE/Sw4XlknRT/plsl3T2oDqMiHH1oroA/n3gN4BJwPeAOb3afAD4fE4vBm4f6XG3YJ/fDPxaTv/JeNjnbPdy4F5gCzBvpMc9zH/Hs4EHgSk5/4qRHncL9nkV8Cc5PQfYNdLjHoL9/rfA2cDDheULgW8BAuYD9w2mv/F4JPGLr/qIiJ8DPV/1UbcIWJvTdwAXSFILxzjU+t3niLg7Ip7J2S1Un0kZzZr5ewb4BHAD8GwrBzcMmtnf9wI3R8RBgIjY1+IxDrVm9jmAk3P6FOCHLRzfsIiIe4EDfTRZBNwWlS3AZEmnD7S/8RgSjb7qY3qpTUQcAQ4Bp7VkdMOjmX2uW0r1m8ho1u8+52H4zIgYC18W1czf8W8Cvynpf0vakt+wPJo1s88fA/5IUhewAfjT1gxtRB3r//c+Hdefk7DWk/RHwDzg90Z6LMNJ0kuATwPvGeGhtNJEqlNO51EdKd4r6Xci4ukRHdXwuhy4NSI+JemNwJcknRURL4z0wEaL8Xgk0cxXffyijaSJVIep+1syuuHR1NebSHoL8FHgHRHxXIvGNlz62+eXA2cB90jaRXXutn0UX7xu5u+4C2iPiOcj4gng/1KFxmjVzD4vBdYDRMR3gBOpvvhvLBvSrzMajyHRzFd9tANLcvpS4K7IK0KjVL/7LOn1wH+jCojRfq4a+tnniDgUEVMjYlZEzKK6DvOOiOgYmeEOWjP/rr9BdRSBpKlUp58eb+Ugh1gz+/wD4AIASf+SKiS6WzrK1msHrsi7nOYDhyJi70A3Nu5ON0Xhqz4kXQd0REQ7sJrqsLST6gLR4pEb8eA1uc//BXgZ8N/zGv0PIuIdIzboQWpyn8eMJvd3I3ChpJ3AUeDPI2LUHiE3uc8fBr4g6d9TXcR+zyj/hQ9JX6MK+6l5reVa4KUAEfF5qmsvC4FO4BngykH1N8r/vMzMbBiNx9NNZmbWJIeEmZkVOSTMzKzIIWFmZkUOCTMzK3JImJlZkUPCzMyK/j+SjtadZCBoVwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# PLOT PREDICTIONS\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sub.prediction, bins=100)\n",
        "plt.title('Test Predictions')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.00263,
          "end_time": "2022-06-19T23:15:39.870669",
          "exception": false,
          "start_time": "2022-06-19T23:15:39.868039",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ofomkRituzly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit\n",
        "!kaggle competitions submit -c amex-default-prediction -f submission_lgb_v14_seed42_fold5.csv -m \"bruto and modified bin features. seed 52 fold 5 From colab\""
      ],
      "metadata": {
        "id": "A6OIgRv0CD76",
        "outputId": "56d04500-800e-4238-e668-6f90b47b0573",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 75.4M/75.4M [00:03<00:00, 24.0MB/s]\n",
            "Successfully submitted to American Express - Default Prediction"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submissions amex-default-prediction"
      ],
      "metadata": {
        "papermill": {
          "duration": 7.116467,
          "end_time": "2022-06-19T23:15:46.98989",
          "exception": false,
          "start_time": "2022-06-19T23:15:39.873423",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%%\n"
        },
        "execution": {
          "iopub.status.busy": "2022-07-15T15:26:18.979284Z",
          "iopub.status.idle": "2022-07-15T15:26:18.979914Z",
          "shell.execute_reply.started": "2022-07-15T15:26:18.979701Z",
          "shell.execute_reply": "2022-07-15T15:26:18.979723Z"
        },
        "trusted": true,
        "id": "Ik1UoN1Auzly",
        "outputId": "38fbfb56-b9af-4c88-8511-571d88ef6c0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fileName                             date                 description                                                       status    publicScore  privateScore  \n",
            "-----------------------------------  -------------------  ----------------------------------------------------------------  --------  -----------  ------------  \n",
            "submission_lgb_v14_seed42_fold5.csv  2022-08-17 09:36:30  bruto and modified bin features. seed 52 fold 5 From colab        complete  0.798                      \n",
            "submission_cat_v14_seed42_fold5.csv  2022-08-17 02:55:14  Run with bruto force and last - mean, last / mean                 complete  0.797                      \n",
            "Amex Default Prediction - Ensemble   2022-08-16 16:08:14  Notebook Amex Default Prediction - Ensemble | Version 77          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-16 16:03:22  Notebook Amex Default Prediction - Ensemble | Version 76          complete  0.799                      \n",
            "submission_xgb_v14_seed42_fold5.csv  2022-08-16 15:51:17  Run with Risk binaries seed 42 fold 5                             complete  0.795                      \n",
            "submission_xgb_v13_seed42_fold5.csv  2022-08-16 12:59:14  Run with Risk binaries seed 42 fold 5                             complete  0.796                      \n",
            "submission_xgb_v12_seed42_fold5.csv  2022-08-16 09:56:54  Run with Risk binaries seed 42 fold 5                             complete  0.795                      \n",
            "Amex Default Prediction - Ensemble   2022-08-15 17:51:16  Notebook Amex Default Prediction - Ensemble | Version 75          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-15 11:08:02  Notebook Amex Default Prediction - Ensemble | Version 73          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-15 11:02:07  Notebook Amex Default Prediction - Ensemble | Version 72          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-15 10:58:37  Notebook Amex Default Prediction - Ensemble | Version 71          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-15 10:55:23  Notebook Amex Default Prediction - Ensemble | Version 70          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-14 12:27:35  Notebook Amex Default Prediction - Ensemble | Version 69          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-14 12:24:14  Notebook Amex Default Prediction - Ensemble | Version 68          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-14 12:21:24  Notebook Amex Default Prediction - Ensemble | Version 67          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-14 12:19:34  Notebook Amex Default Prediction - Ensemble | Version 66          complete  0.798                      \n",
            "Amex Default Prediction - Ensemble   2022-08-13 00:28:10  Notebook Amex Default Prediction - Ensemble | Version 65          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-12 12:22:03  Notebook Amex Default Prediction - Ensemble | Version 64          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-12 12:19:59  Notebook Amex Default Prediction - Ensemble | Version 63          complete  0.799                      \n",
            "submission_lgb_v1_seed42_fold5.csv   2022-08-12 12:11:04  the first version. fe lag plus seed 52 fold 5 From colab          complete  0.798                      \n",
            "submission_lgb_v1_seed42_fold5.csv   2022-08-12 12:10:30  the first version. fe lag plus seed 52 fold 5 From colab          complete  0.798                      \n",
            "submission_cat_v10_seed42_fold5.csv  2022-08-12 07:08:01  Run with bruto force and last - mean, last / mean                 complete  0.796                      \n",
            "submission_xgb_v11_seed42_fold5.csv  2022-08-11 18:37:49  Run with Risk binaries seed 42 fold 5                             complete  0.796                      \n",
            "Amex Default Prediction - Ensemble   2022-08-10 11:28:13  Notebook Amex Default Prediction - Ensemble | Version 62          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-10 11:17:44  Notebook Amex Default Prediction - Ensemble | Version 61          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-10 11:13:39  Notebook Amex Default Prediction - Ensemble | Version 60          complete  0.798                      \n",
            "Amex Default Prediction - Ensemble   2022-08-10 02:06:53  Notebook Amex Default Prediction - Ensemble | Version 58          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-10 02:06:16  Notebook Amex Default Prediction - Ensemble | Version 59          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-09 13:35:30  Notebook Amex Default Prediction - Ensemble | Version 57          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-09 13:28:07  Notebook Amex Default Prediction - Ensemble | Version 56          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-09 13:25:48  Notebook Amex Default Prediction - Ensemble | Version 55          complete  0.799                      \n",
            "submission_lgb_v1_seed42_fold5.csv   2022-08-09 13:14:51  the first version. fe lag plus seed 52 fold 5 From colab          complete  0.798                      \n",
            "submission_cat_v10_seed42_fold5.csv  2022-08-09 12:40:49  Run with bruto force and last - mean, last / mean                 complete  0.796                      \n",
            "Amex Default Prediction - Ensemble   2022-08-08 15:19:46  Notebook Amex Default Prediction - Ensemble | Version 54          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-08 15:17:44  Notebook Amex Default Prediction - Ensemble | Version 53          complete  0.799                      \n",
            "submission_xgb_v10_seed42_fold5.csv  2022-08-08 13:34:01  Run with bruto-force and last - min and max -last seed 42 fold 5  complete  0.796                      \n",
            "submission_xgb_v10_seed42_fold5.csv  2022-08-08 11:25:33  Run with bruto-force and last - min and max -last seed 42 fold 5  complete  0.796                      \n",
            "Amex Default Prediction - Ensemble   2022-08-08 09:16:13  Notebook Amex Default Prediction - Ensemble | Version 52          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-07 10:06:52  Notebook Amex Default Prediction - Ensemble | Version 51          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-07 10:01:11  Notebook Amex Default Prediction - Ensemble | Version 50          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-07 04:25:29  Notebook Amex Default Prediction - Ensemble | Version 49          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-07 04:22:24  Notebook Amex Default Prediction - Ensemble | Version 48          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-07 04:18:56  Notebook Amex Default Prediction - Ensemble | Version 47          complete  0.798                      \n",
            "Amex Default Prediction - Ensemble   2022-08-05 11:27:36  Notebook Amex Default Prediction - Ensemble | Version 46          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-05 11:23:37  Notebook Amex Default Prediction - Ensemble | Version 45          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-04 15:16:57  Notebook Amex Default Prediction - Ensemble | Version 44          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-04 14:56:04  Notebook Amex Default Prediction - Ensemble | Version 43          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-04 14:53:27  Notebook Amex Default Prediction - Ensemble | Version 42          complete  0.799                      \n",
            "submission_cat_v9_seed42_fold5.csv   2022-08-04 14:26:40  Run with max - last                                               complete  0.796                      \n",
            "submission_lgb_v1_seed42_fold5.csv   2022-08-04 14:14:31  the first version. fe lag plus seed 52 fold 5 From colab          complete  0.798                      \n"
          ]
        }
      ]
    }
  ]
}