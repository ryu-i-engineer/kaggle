{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "lag-features-are-all-you-need.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing for colab"
      ],
      "metadata": {
        "id": "whFMYLB1u7rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "MwbPTJbLu1oU",
        "outputId": "2f0d5c98-6813-4cc0-b7cb-32ceb14be8aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.6.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && cp /content/drive/MyDrive/backups/kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Lx3ZHpcHvLK0",
        "outputId": "f840ea1c-17cc-49e7-89d8-fd465a4916b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c amex-default-prediction -f sample_submission.csv\n",
        "!unzip /content/sample_submission.csv.zip"
      ],
      "metadata": {
        "id": "jeIvlVN0vQ08",
        "outputId": "a81a01dc-6a1c-4f43-ed57-862da83e3a94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading sample_submission.csv.zip to /content\n",
            "\r  0% 0.00/32.4M [00:00<?, ?B/s]\r 49% 16.0M/32.4M [00:00<00:00, 166MB/s]\n",
            "\r100% 32.4M/32.4M [00:00<00:00, 227MB/s]\n",
            "Archive:  /content/sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c amex-default-prediction -f train_labels.csv\n",
        "!unzip /content/train_labels.csv.zip"
      ],
      "metadata": {
        "id": "PfGNoPMDxoPk",
        "outputId": "8c77f30f-55a2-4399-c7f4-2607f3f42b22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading train_labels.csv.zip to /content\n",
            "\r  0% 0.00/16.2M [00:00<?, ?B/s]\r 56% 9.00M/16.2M [00:00<00:00, 69.9MB/s]\n",
            "\r100% 16.2M/16.2M [00:00<00:00, 107MB/s] \n",
            "Archive:  /content/train_labels.csv.zip\n",
            "  inflating: train_labels.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training & Inference"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.002398,
          "end_time": "2022-06-19T23:15:37.946621",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.944223",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "672r-QJMuzlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d ryuina/amex-fe-plus2\n",
        "!unzip /content/amex-fe-plus2.zip"
      ],
      "metadata": {
        "id": "C2Kqq_4l7Am1",
        "outputId": "8c4b6671-b05c-4e86-a54b-97850f9b1400",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading amex-fe-plus2.zip to /content\n",
            "100% 3.44G/3.45G [00:24<00:00, 135MB/s]\n",
            "100% 3.45G/3.45G [00:24<00:00, 153MB/s]\n",
            "Archive:  /content/amex-fe-plus2.zip\n",
            "  inflating: test_fe_plus_plus.parquet  \n",
            "  inflating: train_fe_plus_plus.parquet  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Library\n",
        "# ====================================================\n",
        "import os\n",
        "import gc; gc.enable()\n",
        "import joblib\n",
        "import pickle\n",
        "import random\n",
        "import warnings\n",
        "import itertools\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "warnings.filterwarnings('ignore')\n",
        "from itertools import combinations\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "\n",
        "class CFG:\n",
        "    input_dir = '/content/'\n",
        "    seed = 42\n",
        "    n_folds = 5\n",
        "    target = 'target'\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "def read_data():\n",
        "    train = pd.read_parquet(CFG.input_dir + 'train_fe_plus_plus.parquet')\n",
        "    test = pd.read_parquet(CFG.input_dir + 'test_fe_plus_plus.parquet')\n",
        "    return train, test\n",
        "\n",
        "def amex_metric(y_true, y_pred):\n",
        "    labels = np.transpose(np.array([y_true, y_pred]))\n",
        "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
        "    weights = np.where(labels[:,0]==0, 20, 1)\n",
        "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
        "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
        "    gini = [0,0]\n",
        "    for i in [1,0]:\n",
        "        labels = np.transpose(np.array([y_true, y_pred]))\n",
        "        labels = labels[labels[:, i].argsort()[::-1]]\n",
        "        weight = np.where(labels[:,0]==0, 20, 1)\n",
        "        weight_random = np.cumsum(weight / np.sum(weight))\n",
        "        total_pos = np.sum(labels[:, 0] *  weight)\n",
        "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
        "        lorentz = cum_pos_found / total_pos\n",
        "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
        "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
        "\n",
        "def amex_metric_np(preds, target):\n",
        "    indices = np.argsort(preds)[::-1]\n",
        "    preds, target = preds[indices], target[indices]\n",
        "    weight = 20.0 - target * 19.0\n",
        "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
        "    four_pct_mask = cum_norm_weight <= 0.04\n",
        "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
        "    weighted_target = target * weight\n",
        "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
        "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
        "    n_pos = np.sum(target)\n",
        "    n_neg = target.shape[0] - n_pos\n",
        "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
        "    g = gini / gini_max\n",
        "    return 0.5 * (g + d)"
      ],
      "metadata": {
        "papermill": {
          "duration": 1.91354,
          "end_time": "2022-06-19T23:15:39.862701",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.949161",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%%\n"
        },
        "execution": {
          "iopub.status.busy": "2022-07-15T15:26:18.975287Z",
          "iopub.status.idle": "2022-07-15T15:26:18.975786Z",
          "shell.execute_reply.started": "2022-07-15T15:26:18.975552Z",
          "shell.execute_reply": "2022-07-15T15:26:18.975573Z"
        },
        "trusted": true,
        "id": "15l0MOvouzlw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training LightGBM (DART) Model\n",
        "\n",
        "- Final predictions output uploaded as a public dataset. "
      ],
      "metadata": {
        "id": "64hhK5K2uzlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything(CFG.seed)\n",
        "train, test = read_data()"
      ],
      "metadata": {
        "id": "kFQsUkTpemrU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encode categorical features\n",
        "cat_features = [\n",
        "    \"B_30\",\n",
        "    \"B_38\",\n",
        "    \"D_114\",\n",
        "    \"D_116\",\n",
        "    \"D_117\",\n",
        "    \"D_120\",\n",
        "    \"D_126\",\n",
        "    \"D_63\",\n",
        "    \"D_64\",\n",
        "    \"D_66\",\n",
        "    \"D_68\"\n",
        "]\n",
        "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
        "for cat_col in cat_features:\n",
        "    encoder = LabelEncoder()\n",
        "    train[cat_col] = encoder.fit_transform(train[cat_col])\n",
        "    test[cat_col] = encoder.transform(test[cat_col])\n",
        "\n",
        "# Round last float features to 2 decimal place\n",
        "num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
        "num_cols = [col for col in num_cols if 'last' in col]\n",
        "for col in num_cols:\n",
        "    train[col + '_round2'] = train[col].round(2)\n",
        "    test[col + '_round2'] = test[col].round(2)\n",
        "\n",
        "num_cols = [col for col in train.columns if 'last' in col]\n",
        "num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n",
        "for col in num_cols:\n",
        "    try:\n",
        "        train[f'{col}_max-last'] = train[f'{col}_max'] - train[f'{col}_last']\n",
        "        test[f'{col}_max-last'] = test[f'{col}_max'] - test[f'{col}_last']\n",
        "\n",
        "        # train[f'{col}_mean_min'] = train[f'{col}mean'] - train[f'{col}_min']\n",
        "        # test[f'{col}_mean_min'] = test[f'{col}_mean'] - test[f'{col}_min']\n",
        "\n",
        "        train[f'{col}_last_mean'] = train[f'{col}_last'] - train[f'{col}_mean']\n",
        "        test[f'{col}_last_mean'] = test[f'{col}_last'] - test[f'{col}_mean']\n",
        "\n",
        "        train[f'{col}_last_mean_div'] = train[f'{col}_last'] / train[f'{col}_mean']\n",
        "        test[f'{col}_last_mean_div'] = test[f'{col}_last'] / test[f'{col}_mean']\n",
        "    except: pass\n",
        "\n",
        "num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
        "for col in tqdm(num_cols):\n",
        "    train[col] = train[col].astype(np.float16)\n",
        "    test[col] = test[col].astype(np.float16)\n",
        "\n",
        "# Get feature list\n",
        "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]"
      ],
      "metadata": {
        "id": "3apqtSQzbZG1",
        "outputId": "06974d48-2e33-4790-bd64-1c30e5898493",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1629/1629 [09:44<00:00,  2.79it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': \"binary_logloss\",\n",
        "    'boosting': 'dart',\n",
        "    'seed': CFG.seed,\n",
        "    'num_leaves': 100,\n",
        "    'learning_rate': 0.02,\n",
        "    'feature_fraction': 0.20,\n",
        "    'bagging_freq': 10,\n",
        "    'bagging_fraction': 0.50,\n",
        "    'n_jobs': -1,\n",
        "    'lambda_l2': 2,\n",
        "    'min_data_in_leaf': 40,\n",
        "    # 'device_type': 'gpu'\n",
        "    }"
      ],
      "metadata": {
        "id": "S00nxuAZbdBP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lgb_amex_metric(y_pred, y_true):\n",
        "    y_true = y_true.get_label()\n",
        "    return 'amex_metric', amex_metric(y_true, y_pred), True\n",
        "\n",
        "def train_and_evaluate(train):\n",
        "    # Create a numpy array to store out of folds predictions\n",
        "    oof_predictions = np.zeros(len(train))\n",
        "    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
        "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
        "        print(' ')\n",
        "        print('-'*50)\n",
        "        print(f'Training fold {fold} with {len(features)} features...')\n",
        "        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
        "        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
        "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
        "        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
        "        model = lgb.train(\n",
        "            params = params,\n",
        "            train_set = lgb_train,\n",
        "            num_boost_round = 10500,\n",
        "            valid_sets = [lgb_train, lgb_valid],\n",
        "            early_stopping_rounds = 100,\n",
        "            verbose_eval = 500,\n",
        "            feval = lgb_amex_metric\n",
        "            )\n",
        "        # Save best model\n",
        "        joblib.dump(model, f'lgbm_fold{fold}_seed{CFG.seed}.pkl')\n",
        "        # Predict validation\n",
        "        val_pred = model.predict(x_val)\n",
        "        # Add to out of folds array\n",
        "        oof_predictions[val_ind] = val_pred\n",
        "\n",
        "        # Compute fold metric\n",
        "        score = amex_metric(y_val, val_pred)\n",
        "        print(f'Our fold {fold} CV score is {score}')\n",
        "        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid, model\n",
        "        gc.collect()\n",
        "    # Compute out of folds metric\n",
        "    score = amex_metric(train[CFG.target], oof_predictions)\n",
        "    print(f'Our out of folds CV score is {score}')\n",
        "    # Create a dataframe to store out of folds predictions\n",
        "    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
        "    oof_df.to_csv(f'oof_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
        "\n",
        "train_and_evaluate(train)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-07-15T15:26:18.977741Z",
          "iopub.status.idle": "2022-07-15T15:26:18.978405Z",
          "shell.execute_reply.started": "2022-07-15T15:26:18.978196Z",
          "shell.execute_reply": "2022-07-15T15:26:18.978218Z"
        },
        "trusted": true,
        "id": "9p5Z6PX7uzlx",
        "outputId": "c44f93a3-eb0b-4f6d-e4b6-5e6bd016393b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "--------------------------------------------------\n",
            "Training fold 0 with 2177 features...\n",
            "[500]\ttraining's binary_logloss: 0.257194\ttraining's amex_metric: 0.791544\tvalid_1's binary_logloss: 0.261902\tvalid_1's amex_metric: 0.779986\n",
            "[1000]\ttraining's binary_logloss: 0.209963\ttraining's amex_metric: 0.819065\tvalid_1's binary_logloss: 0.223308\tvalid_1's amex_metric: 0.793152\n",
            "[1500]\ttraining's binary_logloss: 0.195689\ttraining's amex_metric: 0.83847\tvalid_1's binary_logloss: 0.21794\tvalid_1's amex_metric: 0.796817\n",
            "[2000]\ttraining's binary_logloss: 0.182803\ttraining's amex_metric: 0.859122\tvalid_1's binary_logloss: 0.215189\tvalid_1's amex_metric: 0.799647\n",
            "[2500]\ttraining's binary_logloss: 0.174145\ttraining's amex_metric: 0.874832\tvalid_1's binary_logloss: 0.214341\tvalid_1's amex_metric: 0.799824\n",
            "[3000]\ttraining's binary_logloss: 0.164837\ttraining's amex_metric: 0.890054\tvalid_1's binary_logloss: 0.213555\tvalid_1's amex_metric: 0.801629\n",
            "[3500]\ttraining's binary_logloss: 0.155811\ttraining's amex_metric: 0.904849\tvalid_1's binary_logloss: 0.213064\tvalid_1's amex_metric: 0.800985\n",
            "[4000]\ttraining's binary_logloss: 0.147674\ttraining's amex_metric: 0.919\tvalid_1's binary_logloss: 0.212805\tvalid_1's amex_metric: 0.801475\n",
            "[4500]\ttraining's binary_logloss: 0.139835\ttraining's amex_metric: 0.932123\tvalid_1's binary_logloss: 0.212678\tvalid_1's amex_metric: 0.801541\n",
            "[5000]\ttraining's binary_logloss: 0.132105\ttraining's amex_metric: 0.943459\tvalid_1's binary_logloss: 0.212599\tvalid_1's amex_metric: 0.801258\n",
            "[5500]\ttraining's binary_logloss: 0.125343\ttraining's amex_metric: 0.953292\tvalid_1's binary_logloss: 0.212713\tvalid_1's amex_metric: 0.800586\n",
            "[6000]\ttraining's binary_logloss: 0.119632\ttraining's amex_metric: 0.961754\tvalid_1's binary_logloss: 0.212811\tvalid_1's amex_metric: 0.801086\n",
            "[6500]\ttraining's binary_logloss: 0.113737\ttraining's amex_metric: 0.969034\tvalid_1's binary_logloss: 0.212858\tvalid_1's amex_metric: 0.802132\n",
            "[7000]\ttraining's binary_logloss: 0.107137\ttraining's amex_metric: 0.976593\tvalid_1's binary_logloss: 0.212941\tvalid_1's amex_metric: 0.802396\n",
            "[7500]\ttraining's binary_logloss: 0.101042\ttraining's amex_metric: 0.982786\tvalid_1's binary_logloss: 0.213158\tvalid_1's amex_metric: 0.801637\n",
            "[8000]\ttraining's binary_logloss: 0.0957452\ttraining's amex_metric: 0.987511\tvalid_1's binary_logloss: 0.213356\tvalid_1's amex_metric: 0.801477\n",
            "[8500]\ttraining's binary_logloss: 0.091342\ttraining's amex_metric: 0.990607\tvalid_1's binary_logloss: 0.21345\tvalid_1's amex_metric: 0.80108\n",
            "[9000]\ttraining's binary_logloss: 0.0864796\ttraining's amex_metric: 0.993547\tvalid_1's binary_logloss: 0.213624\tvalid_1's amex_metric: 0.801652\n",
            "[9500]\ttraining's binary_logloss: 0.0822117\ttraining's amex_metric: 0.995532\tvalid_1's binary_logloss: 0.213979\tvalid_1's amex_metric: 0.800367\n",
            "[10000]\ttraining's binary_logloss: 0.0781192\ttraining's amex_metric: 0.997178\tvalid_1's binary_logloss: 0.214207\tvalid_1's amex_metric: 0.801407\n",
            "[10500]\ttraining's binary_logloss: 0.0746127\ttraining's amex_metric: 0.998328\tvalid_1's binary_logloss: 0.214546\tvalid_1's amex_metric: 0.801366\n",
            "Our fold 0 CV score is 0.8013450348506036\n",
            " \n",
            "--------------------------------------------------\n",
            "Training fold 1 with 2177 features...\n",
            "[500]\ttraining's binary_logloss: 0.256679\ttraining's amex_metric: 0.793285\tvalid_1's binary_logloss: 0.263546\tvalid_1's amex_metric: 0.772293\n",
            "[1000]\ttraining's binary_logloss: 0.209224\ttraining's amex_metric: 0.820553\tvalid_1's binary_logloss: 0.225977\tvalid_1's amex_metric: 0.784805\n",
            "[1500]\ttraining's binary_logloss: 0.194827\ttraining's amex_metric: 0.840364\tvalid_1's binary_logloss: 0.220798\tvalid_1's amex_metric: 0.78853\n",
            "[2000]\ttraining's binary_logloss: 0.182089\ttraining's amex_metric: 0.860473\tvalid_1's binary_logloss: 0.218477\tvalid_1's amex_metric: 0.790715\n",
            "[2500]\ttraining's binary_logloss: 0.173383\ttraining's amex_metric: 0.876801\tvalid_1's binary_logloss: 0.217713\tvalid_1's amex_metric: 0.791242\n",
            "[3000]\ttraining's binary_logloss: 0.163968\ttraining's amex_metric: 0.891871\tvalid_1's binary_logloss: 0.217039\tvalid_1's amex_metric: 0.791172\n",
            "[3500]\ttraining's binary_logloss: 0.154933\ttraining's amex_metric: 0.906539\tvalid_1's binary_logloss: 0.216615\tvalid_1's amex_metric: 0.792846\n",
            "[4000]\ttraining's binary_logloss: 0.146859\ttraining's amex_metric: 0.92029\tvalid_1's binary_logloss: 0.216365\tvalid_1's amex_metric: 0.79218\n",
            "[4500]\ttraining's binary_logloss: 0.138951\ttraining's amex_metric: 0.932997\tvalid_1's binary_logloss: 0.216222\tvalid_1's amex_metric: 0.791875\n",
            "[5000]\ttraining's binary_logloss: 0.131284\ttraining's amex_metric: 0.945057\tvalid_1's binary_logloss: 0.21628\tvalid_1's amex_metric: 0.792052\n",
            "[5500]\ttraining's binary_logloss: 0.12455\ttraining's amex_metric: 0.953981\tvalid_1's binary_logloss: 0.216265\tvalid_1's amex_metric: 0.791965\n",
            "[6000]\ttraining's binary_logloss: 0.118838\ttraining's amex_metric: 0.962535\tvalid_1's binary_logloss: 0.216305\tvalid_1's amex_metric: 0.792355\n",
            "[6500]\ttraining's binary_logloss: 0.112964\ttraining's amex_metric: 0.969445\tvalid_1's binary_logloss: 0.21645\tvalid_1's amex_metric: 0.791526\n",
            "[7000]\ttraining's binary_logloss: 0.106418\ttraining's amex_metric: 0.976785\tvalid_1's binary_logloss: 0.216661\tvalid_1's amex_metric: 0.791412\n",
            "[7500]\ttraining's binary_logloss: 0.100363\ttraining's amex_metric: 0.983373\tvalid_1's binary_logloss: 0.2169\tvalid_1's amex_metric: 0.791962\n",
            "[8000]\ttraining's binary_logloss: 0.0950701\ttraining's amex_metric: 0.987758\tvalid_1's binary_logloss: 0.217181\tvalid_1's amex_metric: 0.792315\n",
            "[8500]\ttraining's binary_logloss: 0.0906797\ttraining's amex_metric: 0.991234\tvalid_1's binary_logloss: 0.21739\tvalid_1's amex_metric: 0.791603\n",
            "[9000]\ttraining's binary_logloss: 0.085832\ttraining's amex_metric: 0.993919\tvalid_1's binary_logloss: 0.217679\tvalid_1's amex_metric: 0.792206\n",
            "[9500]\ttraining's binary_logloss: 0.0815845\ttraining's amex_metric: 0.995943\tvalid_1's binary_logloss: 0.218052\tvalid_1's amex_metric: 0.791991\n",
            "[10000]\ttraining's binary_logloss: 0.0774802\ttraining's amex_metric: 0.997418\tvalid_1's binary_logloss: 0.218323\tvalid_1's amex_metric: 0.791895\n",
            "[10500]\ttraining's binary_logloss: 0.0740379\ttraining's amex_metric: 0.998453\tvalid_1's binary_logloss: 0.218742\tvalid_1's amex_metric: 0.792435\n",
            "Our fold 1 CV score is 0.7924976936964909\n",
            " \n",
            "--------------------------------------------------\n",
            "Training fold 2 with 2177 features...\n",
            "[500]\ttraining's binary_logloss: 0.256685\ttraining's amex_metric: 0.791877\tvalid_1's binary_logloss: 0.263882\tvalid_1's amex_metric: 0.775443\n",
            "[1000]\ttraining's binary_logloss: 0.20929\ttraining's amex_metric: 0.819998\tvalid_1's binary_logloss: 0.225719\tvalid_1's amex_metric: 0.788308\n",
            "[1500]\ttraining's binary_logloss: 0.19506\ttraining's amex_metric: 0.840187\tvalid_1's binary_logloss: 0.220427\tvalid_1's amex_metric: 0.791999\n",
            "[2000]\ttraining's binary_logloss: 0.182159\ttraining's amex_metric: 0.859683\tvalid_1's binary_logloss: 0.217719\tvalid_1's amex_metric: 0.795613\n",
            "[2500]\ttraining's binary_logloss: 0.173501\ttraining's amex_metric: 0.875901\tvalid_1's binary_logloss: 0.216871\tvalid_1's amex_metric: 0.795729\n",
            "[3000]\ttraining's binary_logloss: 0.164232\ttraining's amex_metric: 0.891692\tvalid_1's binary_logloss: 0.216005\tvalid_1's amex_metric: 0.796066\n",
            "[3500]\ttraining's binary_logloss: 0.155204\ttraining's amex_metric: 0.906966\tvalid_1's binary_logloss: 0.215456\tvalid_1's amex_metric: 0.796837\n",
            "[4000]\ttraining's binary_logloss: 0.147132\ttraining's amex_metric: 0.920774\tvalid_1's binary_logloss: 0.215126\tvalid_1's amex_metric: 0.796684\n",
            "[4500]\ttraining's binary_logloss: 0.13921\ttraining's amex_metric: 0.933454\tvalid_1's binary_logloss: 0.215054\tvalid_1's amex_metric: 0.796606\n",
            "[5000]\ttraining's binary_logloss: 0.131485\ttraining's amex_metric: 0.945036\tvalid_1's binary_logloss: 0.215143\tvalid_1's amex_metric: 0.796318\n",
            "[5500]\ttraining's binary_logloss: 0.12468\ttraining's amex_metric: 0.954273\tvalid_1's binary_logloss: 0.215165\tvalid_1's amex_metric: 0.795995\n",
            "[6000]\ttraining's binary_logloss: 0.118968\ttraining's amex_metric: 0.962007\tvalid_1's binary_logloss: 0.215083\tvalid_1's amex_metric: 0.796493\n",
            "[6500]\ttraining's binary_logloss: 0.113127\ttraining's amex_metric: 0.968981\tvalid_1's binary_logloss: 0.215137\tvalid_1's amex_metric: 0.796626\n",
            "[7000]\ttraining's binary_logloss: 0.106525\ttraining's amex_metric: 0.977013\tvalid_1's binary_logloss: 0.21533\tvalid_1's amex_metric: 0.796933\n",
            "[7500]\ttraining's binary_logloss: 0.100443\ttraining's amex_metric: 0.982764\tvalid_1's binary_logloss: 0.215639\tvalid_1's amex_metric: 0.796746\n",
            "[8000]\ttraining's binary_logloss: 0.0951663\ttraining's amex_metric: 0.987433\tvalid_1's binary_logloss: 0.215804\tvalid_1's amex_metric: 0.796329\n",
            "[8500]\ttraining's binary_logloss: 0.0907747\ttraining's amex_metric: 0.99083\tvalid_1's binary_logloss: 0.216052\tvalid_1's amex_metric: 0.796907\n",
            "[9000]\ttraining's binary_logloss: 0.0858918\ttraining's amex_metric: 0.99372\tvalid_1's binary_logloss: 0.21638\tvalid_1's amex_metric: 0.797313\n",
            "[9500]\ttraining's binary_logloss: 0.0816482\ttraining's amex_metric: 0.995813\tvalid_1's binary_logloss: 0.216718\tvalid_1's amex_metric: 0.796914\n",
            "[10000]\ttraining's binary_logloss: 0.0775711\ttraining's amex_metric: 0.997239\tvalid_1's binary_logloss: 0.217026\tvalid_1's amex_metric: 0.797364\n",
            "[10500]\ttraining's binary_logloss: 0.0741353\ttraining's amex_metric: 0.998237\tvalid_1's binary_logloss: 0.217473\tvalid_1's amex_metric: 0.796562\n",
            "Our fold 2 CV score is 0.7965625372041211\n",
            " \n",
            "--------------------------------------------------\n",
            "Training fold 3 with 2177 features...\n",
            "[500]\ttraining's binary_logloss: 0.256408\ttraining's amex_metric: 0.793229\tvalid_1's binary_logloss: 0.264871\tvalid_1's amex_metric: 0.770092\n",
            "[1000]\ttraining's binary_logloss: 0.209047\ttraining's amex_metric: 0.821339\tvalid_1's binary_logloss: 0.226943\tvalid_1's amex_metric: 0.78365\n",
            "[1500]\ttraining's binary_logloss: 0.194768\ttraining's amex_metric: 0.841437\tvalid_1's binary_logloss: 0.221464\tvalid_1's amex_metric: 0.788626\n",
            "[2000]\ttraining's binary_logloss: 0.181952\ttraining's amex_metric: 0.860592\tvalid_1's binary_logloss: 0.218931\tvalid_1's amex_metric: 0.79081\n",
            "[2500]\ttraining's binary_logloss: 0.173222\ttraining's amex_metric: 0.876083\tvalid_1's binary_logloss: 0.218156\tvalid_1's amex_metric: 0.790647\n",
            "[3000]\ttraining's binary_logloss: 0.163932\ttraining's amex_metric: 0.891629\tvalid_1's binary_logloss: 0.217244\tvalid_1's amex_metric: 0.791686\n",
            "[3500]\ttraining's binary_logloss: 0.154944\ttraining's amex_metric: 0.906477\tvalid_1's binary_logloss: 0.216829\tvalid_1's amex_metric: 0.791339\n",
            "[4000]\ttraining's binary_logloss: 0.146862\ttraining's amex_metric: 0.919994\tvalid_1's binary_logloss: 0.216579\tvalid_1's amex_metric: 0.792499\n",
            "[4500]\ttraining's binary_logloss: 0.138988\ttraining's amex_metric: 0.933027\tvalid_1's binary_logloss: 0.216453\tvalid_1's amex_metric: 0.793125\n",
            "[5000]\ttraining's binary_logloss: 0.131342\ttraining's amex_metric: 0.944308\tvalid_1's binary_logloss: 0.216273\tvalid_1's amex_metric: 0.791547\n",
            "[5500]\ttraining's binary_logloss: 0.124591\ttraining's amex_metric: 0.954225\tvalid_1's binary_logloss: 0.21633\tvalid_1's amex_metric: 0.792276\n",
            "[6000]\ttraining's binary_logloss: 0.11888\ttraining's amex_metric: 0.962027\tvalid_1's binary_logloss: 0.216427\tvalid_1's amex_metric: 0.791895\n",
            "[6500]\ttraining's binary_logloss: 0.113015\ttraining's amex_metric: 0.969582\tvalid_1's binary_logloss: 0.216493\tvalid_1's amex_metric: 0.791438\n",
            "[7000]\ttraining's binary_logloss: 0.10643\ttraining's amex_metric: 0.9771\tvalid_1's binary_logloss: 0.216612\tvalid_1's amex_metric: 0.790315\n",
            "[7500]\ttraining's binary_logloss: 0.100331\ttraining's amex_metric: 0.983062\tvalid_1's binary_logloss: 0.216819\tvalid_1's amex_metric: 0.791568\n",
            "[8000]\ttraining's binary_logloss: 0.0950264\ttraining's amex_metric: 0.98777\tvalid_1's binary_logloss: 0.217078\tvalid_1's amex_metric: 0.791446\n",
            "[8500]\ttraining's binary_logloss: 0.0906107\ttraining's amex_metric: 0.991119\tvalid_1's binary_logloss: 0.217287\tvalid_1's amex_metric: 0.790607\n",
            "[9000]\ttraining's binary_logloss: 0.0857522\ttraining's amex_metric: 0.993898\tvalid_1's binary_logloss: 0.217576\tvalid_1's amex_metric: 0.792339\n",
            "[9500]\ttraining's binary_logloss: 0.0814796\ttraining's amex_metric: 0.99591\tvalid_1's binary_logloss: 0.217881\tvalid_1's amex_metric: 0.791842\n",
            "[10000]\ttraining's binary_logloss: 0.0774274\ttraining's amex_metric: 0.997507\tvalid_1's binary_logloss: 0.218265\tvalid_1's amex_metric: 0.791573\n",
            "[10500]\ttraining's binary_logloss: 0.0739739\ttraining's amex_metric: 0.998332\tvalid_1's binary_logloss: 0.218611\tvalid_1's amex_metric: 0.791668\n",
            "Our fold 3 CV score is 0.7916472302751891\n",
            " \n",
            "--------------------------------------------------\n",
            "Training fold 4 with 2177 features...\n",
            "[500]\ttraining's binary_logloss: 0.257105\ttraining's amex_metric: 0.792341\tvalid_1's binary_logloss: 0.263148\tvalid_1's amex_metric: 0.775725\n",
            "[1000]\ttraining's binary_logloss: 0.209686\ttraining's amex_metric: 0.820068\tvalid_1's binary_logloss: 0.224632\tvalid_1's amex_metric: 0.787844\n",
            "[1500]\ttraining's binary_logloss: 0.195467\ttraining's amex_metric: 0.840102\tvalid_1's binary_logloss: 0.219215\tvalid_1's amex_metric: 0.791643\n",
            "[2000]\ttraining's binary_logloss: 0.182581\ttraining's amex_metric: 0.860346\tvalid_1's binary_logloss: 0.216437\tvalid_1's amex_metric: 0.794607\n",
            "[2500]\ttraining's binary_logloss: 0.173822\ttraining's amex_metric: 0.87555\tvalid_1's binary_logloss: 0.215582\tvalid_1's amex_metric: 0.795803\n",
            "[3000]\ttraining's binary_logloss: 0.164519\ttraining's amex_metric: 0.890587\tvalid_1's binary_logloss: 0.214779\tvalid_1's amex_metric: 0.796708\n",
            "[3500]\ttraining's binary_logloss: 0.155459\ttraining's amex_metric: 0.906271\tvalid_1's binary_logloss: 0.214366\tvalid_1's amex_metric: 0.796061\n",
            "[4000]\ttraining's binary_logloss: 0.147343\ttraining's amex_metric: 0.919667\tvalid_1's binary_logloss: 0.214057\tvalid_1's amex_metric: 0.795954\n",
            "[4500]\ttraining's binary_logloss: 0.139447\ttraining's amex_metric: 0.932392\tvalid_1's binary_logloss: 0.213838\tvalid_1's amex_metric: 0.796694\n",
            "[5000]\ttraining's binary_logloss: 0.13181\ttraining's amex_metric: 0.943819\tvalid_1's binary_logloss: 0.213645\tvalid_1's amex_metric: 0.797171\n",
            "[5500]\ttraining's binary_logloss: 0.125054\ttraining's amex_metric: 0.953342\tvalid_1's binary_logloss: 0.213646\tvalid_1's amex_metric: 0.796907\n",
            "[6000]\ttraining's binary_logloss: 0.119316\ttraining's amex_metric: 0.962056\tvalid_1's binary_logloss: 0.21361\tvalid_1's amex_metric: 0.797409\n",
            "[6500]\ttraining's binary_logloss: 0.113403\ttraining's amex_metric: 0.969095\tvalid_1's binary_logloss: 0.213682\tvalid_1's amex_metric: 0.796746\n",
            "[7000]\ttraining's binary_logloss: 0.106851\ttraining's amex_metric: 0.976594\tvalid_1's binary_logloss: 0.213916\tvalid_1's amex_metric: 0.795988\n",
            "[7500]\ttraining's binary_logloss: 0.100769\ttraining's amex_metric: 0.982537\tvalid_1's binary_logloss: 0.214029\tvalid_1's amex_metric: 0.796454\n",
            "[8000]\ttraining's binary_logloss: 0.0954548\ttraining's amex_metric: 0.987305\tvalid_1's binary_logloss: 0.214302\tvalid_1's amex_metric: 0.796562\n",
            "[8500]\ttraining's binary_logloss: 0.0910389\ttraining's amex_metric: 0.990826\tvalid_1's binary_logloss: 0.214458\tvalid_1's amex_metric: 0.796575\n",
            "[9000]\ttraining's binary_logloss: 0.0861913\ttraining's amex_metric: 0.993696\tvalid_1's binary_logloss: 0.214657\tvalid_1's amex_metric: 0.797256\n",
            "[9500]\ttraining's binary_logloss: 0.081944\ttraining's amex_metric: 0.995752\tvalid_1's binary_logloss: 0.214845\tvalid_1's amex_metric: 0.797842\n",
            "[10000]\ttraining's binary_logloss: 0.0778893\ttraining's amex_metric: 0.997283\tvalid_1's binary_logloss: 0.215076\tvalid_1's amex_metric: 0.797196\n",
            "[10500]\ttraining's binary_logloss: 0.0744363\ttraining's amex_metric: 0.998284\tvalid_1's binary_logloss: 0.215338\tvalid_1's amex_metric: 0.796875\n",
            "Our fold 4 CV score is 0.7967900947844639\n",
            "Our out of folds CV score is 0.795905311811925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del train\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "id": "P2llPNqqOKTT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.018388,
          "end_time": "2022-07-15T16:48:45.862462",
          "exception": false,
          "start_time": "2022-07-15T16:48:45.844074",
          "status": "completed"
        },
        "tags": [],
        "id": "bf46dad6"
      },
      "source": [
        "# Test part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T16:48:45.901178Z",
          "iopub.status.busy": "2022-07-15T16:48:45.900848Z",
          "iopub.status.idle": "2022-07-15T16:48:45.907526Z",
          "shell.execute_reply": "2022-07-15T16:48:45.906709Z"
        },
        "papermill": {
          "duration": 0.027751,
          "end_time": "2022-07-15T16:48:45.909278",
          "exception": false,
          "start_time": "2022-07-15T16:48:45.881527",
          "status": "completed"
        },
        "tags": [],
        "id": "c28f1826"
      },
      "outputs": [],
      "source": [
        "# CALCULATE SIZE OF EACH SEPARATE TEST PART\n",
        "def get_rows(customers, test, NUM_PARTS = 4, verbose = ''):\n",
        "    chunk = len(customers)//NUM_PARTS\n",
        "    if verbose != '':\n",
        "        print(f'We will process {verbose} data as {NUM_PARTS} separate parts.')\n",
        "        print(f'There will be {chunk} customers in each part (except the last part).')\n",
        "        print('Below are number of rows in each part:')\n",
        "    rows = []\n",
        "\n",
        "    for k in range(NUM_PARTS):\n",
        "        if k==NUM_PARTS-1: cc = customers[k*chunk:]\n",
        "        else: cc = customers[k*chunk:(k+1)*chunk]\n",
        "        s = test.loc[test.customer_ID.isin(cc)].shape[0]\n",
        "        rows.append(s)\n",
        "    if verbose != '': print( rows )\n",
        "    return rows,chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T16:48:45.947705Z",
          "iopub.status.busy": "2022-07-15T16:48:45.947377Z",
          "iopub.status.idle": "2022-07-15T16:48:47.039525Z",
          "shell.execute_reply": "2022-07-15T16:48:47.038640Z"
        },
        "papermill": {
          "duration": 1.113806,
          "end_time": "2022-07-15T16:48:47.041416",
          "exception": false,
          "start_time": "2022-07-15T16:48:45.927610",
          "status": "completed"
        },
        "tags": [],
        "id": "8c7e70c5",
        "outputId": "31f1b6d9-bff2-4470-ee3c-4d51eedaa362",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We will process test data as 4 separate parts.\n",
            "There will be 231155 customers in each part (except the last part).\n",
            "Below are number of rows in each part:\n",
            "[231155, 231155, 231155, 231156]\n"
          ]
        }
      ],
      "source": [
        "# COMPUTE SIZE OF 4 PARTS FOR TEST DATA\n",
        "NUM_PARTS = 4\n",
        "\n",
        "customers = test[['customer_ID']].drop_duplicates().sort_index().values.flatten()\n",
        "rows,num_cust = get_rows(customers, test[['customer_ID']], NUM_PARTS = NUM_PARTS, verbose = 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T16:48:47.081924Z",
          "iopub.status.busy": "2022-07-15T16:48:47.081615Z",
          "iopub.status.idle": "2022-07-15T16:50:55.407348Z",
          "shell.execute_reply": "2022-07-15T16:50:55.406352Z"
        },
        "papermill": {
          "duration": 128.349422,
          "end_time": "2022-07-15T16:50:55.410249",
          "exception": false,
          "start_time": "2022-07-15T16:48:47.060827",
          "status": "completed"
        },
        "tags": [],
        "id": "9cf53fd3",
        "outputId": "58ee2f54-cb7f-4967-9f1c-5380b8d2a79a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reading test data...\n",
            "=> Test part 1 has shape (231155, 2177)\n",
            "\n",
            "Reading test data...\n",
            "=> Test part 2 has shape (231155, 2177)\n",
            "\n",
            "Reading test data...\n",
            "=> Test part 3 has shape (231155, 2177)\n",
            "\n",
            "Reading test data...\n",
            "=> Test part 4 has shape (231156, 2177)\n"
          ]
        }
      ],
      "source": [
        "# INFER TEST DATA IN PARTS\n",
        "skip_rows = 0\n",
        "skip_cust = 0\n",
        "test_preds = []\n",
        "\n",
        "for k in range(NUM_PARTS):\n",
        "    \n",
        "    # READ PART OF TEST DATA\n",
        "    print(f'\\nReading test data...')\n",
        "    test_copy = test.iloc[skip_rows:skip_rows+rows[k]].copy()\n",
        "    test_copy = test_copy.set_index('customer_ID')\n",
        "    skip_rows += rows[k]\n",
        "    print(f'=> Test part {k+1} has shape', test_copy.shape )\n",
        "    \n",
        "    # PROCESS AND FEATURE ENGINEER PART OF TEST DATA\n",
        "    if k==NUM_PARTS-1: test_copy = test_copy.loc[customers[skip_cust:]]\n",
        "    else: test_copy = test_copy.loc[customers[skip_cust:skip_cust+num_cust]]\n",
        "    skip_cust += num_cust\n",
        "        \n",
        "    # INFER XGB MODELS ON TEST DATA\n",
        "    model = joblib.load(f'lgbm_fold0_seed{CFG.seed}.pkl')\n",
        "    preds = model.predict(test_copy)\n",
        "    for f in range(1,CFG.n_folds):\n",
        "        model = joblib.load(f'lgbm_fold{f}_seed{CFG.seed}.pkl')\n",
        "        preds += model.predict(test_copy)\n",
        "    preds /= CFG.n_folds\n",
        "    test_preds.append(preds)\n",
        "\n",
        "    # CLEAN MEMORY\n",
        "    del test_copy, model\n",
        "    _ = gc.collect()\n",
        "\n",
        "del test\n",
        "_ = gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.067515,
          "end_time": "2022-07-15T16:50:55.538577",
          "exception": false,
          "start_time": "2022-07-15T16:50:55.471062",
          "status": "completed"
        },
        "tags": [],
        "id": "02259545"
      },
      "source": [
        "# Submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T16:50:55.628196Z",
          "iopub.status.busy": "2022-07-15T16:50:55.627855Z",
          "iopub.status.idle": "2022-07-15T16:51:02.864876Z",
          "shell.execute_reply": "2022-07-15T16:51:02.864114Z"
        },
        "papermill": {
          "duration": 7.268354,
          "end_time": "2022-07-15T16:51:02.866646",
          "exception": false,
          "start_time": "2022-07-15T16:50:55.598292",
          "status": "completed"
        },
        "tags": [],
        "id": "00d908fd",
        "outputId": "63f45303-9325-428f-ba53-73bc3fb35e02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file shape is (924621, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         customer_ID  prediction\n",
              "0  00000469ba478561f23a92a868bd366de6f6527a684c9a...    0.019091\n",
              "1  00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...    0.000522\n",
              "2  0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...    0.022647\n",
              "3  00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...    0.133822\n",
              "4  00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...    0.920366"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d20eb41-1543-4a00-a9a7-3d66998730b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_ID</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
              "      <td>0.019091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...</td>\n",
              "      <td>0.000522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...</td>\n",
              "      <td>0.022647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...</td>\n",
              "      <td>0.133822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...</td>\n",
              "      <td>0.920366</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d20eb41-1543-4a00-a9a7-3d66998730b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d20eb41-1543-4a00-a9a7-3d66998730b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d20eb41-1543-4a00-a9a7-3d66998730b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# WRITE SUBMISSION FILE\n",
        "test = pd.DataFrame(index=customers,data={'prediction': np.concatenate(test_preds)})\n",
        "sub = pd.read_csv('sample_submission.csv')[['customer_ID']]\n",
        "sub['customer_ID_hash'] = sub['customer_ID'].copy()\n",
        "sub = sub.set_index('customer_ID_hash')\n",
        "sub = sub.merge(test[['prediction']], left_index=True, right_index=True, how='left')\n",
        "sub = sub.reset_index(drop=True)\n",
        "\n",
        "# DISPLAY PREDICTIONS\n",
        "sub.to_csv(f'submission_lgb_v1_seed{CFG.seed}_fold{CFG.n_folds}.csv',index=False)\n",
        "print('Submission file shape is', sub.shape )\n",
        "sub.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T16:51:02.918871Z",
          "iopub.status.busy": "2022-07-15T16:51:02.918494Z",
          "iopub.status.idle": "2022-07-15T16:51:03.267833Z",
          "shell.execute_reply": "2022-07-15T16:51:03.266949Z"
        },
        "papermill": {
          "duration": 0.374502,
          "end_time": "2022-07-15T16:51:03.269960",
          "exception": false,
          "start_time": "2022-07-15T16:51:02.895458",
          "status": "completed"
        },
        "tags": [],
        "id": "533e5941",
        "outputId": "45907e07-bc55-4e8a-fa0b-3b7ac5aa87ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# PLOT PREDICTIONS\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sub.prediction, bins=100)\n",
        "plt.title('Test Predictions')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.00263,
          "end_time": "2022-06-19T23:15:39.870669",
          "exception": false,
          "start_time": "2022-06-19T23:15:39.868039",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ofomkRituzly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit\n",
        "!kaggle competitions submit -c amex-default-prediction -f submission_lgb_v1_seed42_fold5.csv -m \"the first version. fe lag plus seed 52 fold 5 From colab\""
      ],
      "metadata": {
        "id": "A6OIgRv0CD76",
        "outputId": "7d61f2bf-f56c-4c35-8ed0-fb15157f6ece",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 75.4M/75.4M [00:02<00:00, 32.0MB/s]\n",
            "User cancelled operation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submissions amex-default-prediction"
      ],
      "metadata": {
        "papermill": {
          "duration": 7.116467,
          "end_time": "2022-06-19T23:15:46.98989",
          "exception": false,
          "start_time": "2022-06-19T23:15:39.873423",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%%\n"
        },
        "execution": {
          "iopub.status.busy": "2022-07-15T15:26:18.979284Z",
          "iopub.status.idle": "2022-07-15T15:26:18.979914Z",
          "shell.execute_reply.started": "2022-07-15T15:26:18.979701Z",
          "shell.execute_reply": "2022-07-15T15:26:18.979723Z"
        },
        "trusted": true,
        "id": "Ik1UoN1Auzly",
        "outputId": "5fb33007-7d65-4885-dccd-4fff2c80d0cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fileName                             date                 description                                                       status    publicScore  privateScore  \n",
            "-----------------------------------  -------------------  ----------------------------------------------------------------  --------  -----------  ------------  \n",
            "submission_lgb_v1_seed42_fold5.csv   2022-08-12 12:11:04  the first version. fe lag plus seed 52 fold 5 From colab          pending                              \n",
            "submission_lgb_v1_seed42_fold5.csv   2022-08-12 12:10:30  the first version. fe lag plus seed 52 fold 5 From colab          complete  0.798                      \n",
            "submission_cat_v10_seed42_fold5.csv  2022-08-12 07:08:01  Run with bruto force and last - mean, last / mean                 complete  0.796                      \n",
            "submission_xgb_v11_seed42_fold5.csv  2022-08-11 18:37:49  Run with Risk binaries seed 42 fold 5                             complete  0.796                      \n",
            "Amex Default Prediction - Ensemble   2022-08-10 11:28:13  Notebook Amex Default Prediction - Ensemble | Version 62          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-10 11:17:44  Notebook Amex Default Prediction - Ensemble | Version 61          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-10 11:13:39  Notebook Amex Default Prediction - Ensemble | Version 60          complete  0.798                      \n",
            "Amex Default Prediction - Ensemble   2022-08-10 02:06:53  Notebook Amex Default Prediction - Ensemble | Version 58          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-10 02:06:16  Notebook Amex Default Prediction - Ensemble | Version 59          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-09 13:35:30  Notebook Amex Default Prediction - Ensemble | Version 57          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-09 13:28:07  Notebook Amex Default Prediction - Ensemble | Version 56          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-09 13:25:48  Notebook Amex Default Prediction - Ensemble | Version 55          complete  0.799                      \n",
            "submission_lgb_v1_seed42_fold5.csv   2022-08-09 13:14:51  the first version. fe lag plus seed 52 fold 5 From colab          complete  0.798                      \n",
            "submission_cat_v10_seed42_fold5.csv  2022-08-09 12:40:49  Run with bruto force and last - mean, last / mean                 complete  0.796                      \n",
            "Amex Default Prediction - Ensemble   2022-08-08 15:19:46  Notebook Amex Default Prediction - Ensemble | Version 54          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-08 15:17:44  Notebook Amex Default Prediction - Ensemble | Version 53          complete  0.799                      \n",
            "submission_xgb_v10_seed42_fold5.csv  2022-08-08 13:34:01  Run with bruto-force and last - min and max -last seed 42 fold 5  complete  0.796                      \n",
            "submission_xgb_v10_seed42_fold5.csv  2022-08-08 11:25:33  Run with bruto-force and last - min and max -last seed 42 fold 5  complete  0.796                      \n",
            "Amex Default Prediction - Ensemble   2022-08-08 09:16:13  Notebook Amex Default Prediction - Ensemble | Version 52          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-07 10:06:52  Notebook Amex Default Prediction - Ensemble | Version 51          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-07 10:01:11  Notebook Amex Default Prediction - Ensemble | Version 50          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-07 04:25:29  Notebook Amex Default Prediction - Ensemble | Version 49          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-07 04:22:24  Notebook Amex Default Prediction - Ensemble | Version 48          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-07 04:18:56  Notebook Amex Default Prediction - Ensemble | Version 47          complete  0.798                      \n",
            "Amex Default Prediction - Ensemble   2022-08-05 11:27:36  Notebook Amex Default Prediction - Ensemble | Version 46          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-05 11:23:37  Notebook Amex Default Prediction - Ensemble | Version 45          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-04 15:16:57  Notebook Amex Default Prediction - Ensemble | Version 44          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-04 14:56:04  Notebook Amex Default Prediction - Ensemble | Version 43          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-04 14:53:27  Notebook Amex Default Prediction - Ensemble | Version 42          complete  0.799                      \n",
            "submission_cat_v9_seed42_fold5.csv   2022-08-04 14:26:40  Run with max - last                                               complete  0.796                      \n",
            "submission_lgb_v1_seed42_fold5.csv   2022-08-04 14:14:31  the first version. fe lag plus seed 52 fold 5 From colab          complete  0.798                      \n",
            "Amex Default Prediction - Ensemble   2022-08-03 11:51:07  Notebook Amex Default Prediction - Ensemble | Version 40          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-03 11:43:47  Notebook Amex Default Prediction - Ensemble | Version 38          complete  0.799                      \n",
            "Amex Default Prediction - Ensemble   2022-08-03 11:43:35  Notebook Amex Default Prediction - Ensemble | Version 38          complete  0.798                      \n",
            "Amex Default Prediction - Ensemble   2022-08-03 11:40:52  Notebook Amex Default Prediction - Ensemble | Version 37          complete  0.798                      \n",
            "Amex Default Prediction - Ensemble   2022-08-03 11:33:14  Notebook Amex Default Prediction - Ensemble | Version 36          complete  0.799                      \n",
            "submission_xgb_v8_seed42_fold5.csv   2022-08-02 17:47:50  Run with (last - first) / s_2 seed 42 fold 5                      complete  0.795                      \n",
            "submission_cat_v9_seed42_fold5.csv   2022-08-02 15:17:24  Run with max - last                                               complete  0.796                      \n",
            "submission_cat_v7_seed42_fold5.csv   2022-08-01 06:24:15  Run with max - last                                               complete  0.796                      \n",
            "Amex Default Prediction - Ensemble   2022-07-30 15:42:45  Notebook Amex Default Prediction - Ensemble | Version 35          complete  0.798                      \n",
            "Amex Default Prediction - Ensemble   2022-07-30 15:38:09  rank                                                              complete  0.798                      \n",
            "Amex Default Prediction - Ensemble   2022-07-30 15:36:03  mean ver                                                          complete  0.798                      \n",
            "Amex Default Prediction - Ensemble   2022-07-30 15:19:03  Notebook Amex Default Prediction - Ensemble | Version 32          complete  0.798                      \n",
            "Amex Default Prediction - Ensemble   2022-07-30 10:03:47  Notebook Amex Default Prediction - Ensemble | Version 31          complete  0.798                      \n",
            "Amex Default Prediction - Ensemble   2022-07-29 11:37:23  Notebook Amex Default Prediction - Ensemble | Version 30          complete  0.798                      \n",
            "submission_cat_v7_seed42_fold5.csv   2022-07-29 04:02:04  Run with seed 42 fold 5 last / s2                                 complete  0.796                      \n",
            "Amex Default Prediction - Ensemble   2022-07-28 14:38:46  Notebook Amex Default Prediction - Ensemble | Version 29          complete  0.798                      \n",
            "Amex Default Prediction - Ensemble   2022-07-28 14:34:35  Notebook Amex Default Prediction - Ensemble | Version 28          complete  0.798                      \n",
            "Amex Default Prediction - Ensemble   2022-07-28 13:10:11  Notebook Amex Default Prediction - Ensemble | Version 27          complete  0.798                      \n",
            "submission_lgb_v1_seed42_fold5.csv   2022-07-28 12:43:40  the first version. fe lag plus seed 52 fold 5 From colab          complete  0.798                      \n"
          ]
        }
      ]
    }
  ]
}